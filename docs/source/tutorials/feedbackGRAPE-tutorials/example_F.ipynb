{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8707b5d9",
   "metadata": {},
   "source": [
    "# Stabilization of 5 qubits using a RNN control model\n",
    "In this example, we train a RNN model to stabilize 5 qubits against decay and decoherence using 4 generalized measurements plus a unitary per error correction cycle and compare its performance to the uncontrolled case. Mathematically, the model is powerful enough to express Laflamme code. To demonstrate GPU acceleration, we chose a larger batch size and fewer training iterations. The code takes 16 min on a NVIDIA Quadro RTX 6000 node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"../../../..\")\n",
    "\n",
    "# ruff: noqa\n",
    "from feedback_grape.fgrape import optimize_pulse\n",
    "from feedback_grape.fgrape import Gate, Decay # type: ignore\n",
    "from feedback_grape.utils.states import basis # type: ignore\n",
    "from feedback_grape.utils.fidelity import ket2dm # type: ignore\n",
    "from feedback_grape.utils.operators import sigmaz, sigmam # type: ignore\n",
    "from feedback_grape.utils.modeling import embed # type: ignore\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d195354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "N_qubits = 5\n",
    "N_meas = 4\n",
    "gamma_z = 0.1 # dephasing rate\n",
    "gamma_m = 0.1 # decay rate\n",
    "psi_target = (basis(2**N_qubits, 0) + basis(2**N_qubits, 2**N_qubits - 1)) / jnp.sqrt(2) # (|11...1> + |00...0>)/sqrt(2)\n",
    "rho_target = ket2dm(psi_target)\n",
    "\n",
    "# Model parameters\n",
    "rnn_hidden_size = 16\n",
    "\n",
    "# Training parameters\n",
    "num_time_steps = 3\n",
    "reward_weights = [1.0]*num_time_steps\n",
    "convergence_threshold = None # no early stopping\n",
    "N_training_iterations = 250 # relatively small number of iterations for demo purposes\n",
    "batch_size = 128\n",
    "learning_rate = 3e-3\n",
    "\n",
    "# Evaluation parameters\n",
    "eval_time_steps = 10\n",
    "eval_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c83722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the operators we need\n",
    "def generate_hermitian(params, dim):\n",
    "    assert len(params) == dim**2, \"Number of real parameters must be dim^2 for an NxN Hermitian matrix.\"\n",
    "    \n",
    "    X = params.reshape(dim, dim)\n",
    "\n",
    "    # Real part: take the symmetric part of X\n",
    "    Re = 0.5 * (X + X.T)\n",
    "\n",
    "    # Imag part: take the antisymmetric part of X\n",
    "    Im = 0.5 * (X - X.T)\n",
    "\n",
    "    # Build Hermitian matrix: Herm = Re + 1j * Im\n",
    "    H = Re + 1j * Im\n",
    "\n",
    "    return H\n",
    "\n",
    "def generate_unitary(params, dim):\n",
    "    assert len(params) == dim**2, \"Number of real parameters must be dim^2 for an NxN unitary matrix.\"\n",
    "\n",
    "    H = generate_hermitian(params, dim)\n",
    "    return jax.scipy.linalg.expm(-1j * H)\n",
    "\n",
    "def generate_povm(measurement_outcome, params, dim):\n",
    "    \"\"\" \n",
    "        Generate a 2-outcome POVM elements M_0 and M_1 for a system with Hilbert space dimension dim.\n",
    "        This function should parametrize all such POVMs up to unitary equivalence, i.e., M_i -> U M_i for some unitary U.\n",
    "        I.e it parametrizes all pairs (M_0, M_1) such that M_0 M_0† + M_1 M_1† = I.\n",
    "\n",
    "        measurement_outcome: 0 or 1, indicating which POVM element to generate.\n",
    "        params: list of dim^(dim+1) real parameters.\n",
    "\n",
    "        when measurement_outcome == 1:\n",
    "            M_1 = S D S†\n",
    "        when measurement_outcome == -1:\n",
    "            M_0 = S (I - D) S†\n",
    "\n",
    "        where S is a unitary parametrized by dim^2 parameters, and D is a diagonal matrix with eigenvalues parametrized by dim parameters.\n",
    "    \"\"\"\n",
    "    assert len(params) == dim * (dim + 1), \"Number of real parameters must be N * (N + 1) for an NxN POVM element.\"\n",
    "\n",
    "    S = generate_unitary(params[0:dim*dim], dim=dim) # All parameters for unitary\n",
    "\n",
    "    d_vec = jnp.astype(jnp.square(jnp.sin( params[dim*dim:dim*(dim+1)] )), jnp.complex128) # Last #dim parameters for eigenvalues\n",
    "    d_vec = 1e-8 + (1 - 2e-8) * d_vec # Avoid exactly 0 or 1 eigenvalues for numerical stability\n",
    "\n",
    "    # jnp.multiply is fast way to \"matrix @ diagonal matrix\" multiplication, especially for large matrices\n",
    "    return jnp.where(measurement_outcome == 1,\n",
    "        jnp.multiply(S, d_vec) @ S.conj().T,\n",
    "        jnp.multiply(S, jnp.sqrt(1 - jnp.square(d_vec))) @ S.conj().T\n",
    "    )\n",
    "\n",
    "def jump_ops(N_qubits, gamma_z, gamma_m):\n",
    "    return [\n",
    "        gamma_z**0.5 * embed(sigmaz(), 1, (2**j, 2, 2**(N_qubits - j - 1)))\n",
    "        for j in range(N_qubits)\n",
    "    ] + [\n",
    "        gamma_m**0.5 * embed(sigmam(), 1, (2**j, 2, 2**(N_qubits - j - 1)))\n",
    "        for j in range(N_qubits)\n",
    "    ]\n",
    "\n",
    "# All the gates we need\n",
    "key = jax.random.PRNGKey(2)\n",
    "dim = 2**N_qubits # Hilbert space dimension\n",
    "\n",
    "decay_gate = Decay(\n",
    "    c_ops=jump_ops(N_qubits, gamma_z, gamma_m),\n",
    ")\n",
    "\n",
    "N_unitary_params = dim**2\n",
    "U_gate = Gate(\n",
    "    gate=lambda params: generate_unitary(params, dim=dim),\n",
    "    initial_params = jax.random.uniform(key, (N_unitary_params,), minval=0.0, maxval=1.0),\n",
    "    measurement_flag = False\n",
    ")\n",
    "\n",
    "N_msmt_params = dim * (dim + 1)\n",
    "msmt_gate = Gate(\n",
    "    gate=lambda msmt, params: generate_povm(msmt, params, dim=dim),\n",
    "    initial_params = jax.random.uniform(key, (N_msmt_params,), minval=0.0, maxval=2*jnp.pi),\n",
    "    measurement_flag = True\n",
    ")\n",
    "\n",
    "system_params = [decay_gate] + [msmt_gate]*N_meas + [U_gate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Loss: -0.414569, T=33s, eta=744s\n",
      "Iteration 20, Loss: -0.417313, T=68s, eta=749s\n",
      "Iteration 30, Loss: -0.443282, T=102s, eta=730s\n",
      "Iteration 40, Loss: -0.386187, T=136s, eta=702s\n",
      "Iteration 50, Loss: -0.016632, T=170s, eta=672s\n",
      "Iteration 60, Loss: 0.313386, T=204s, eta=641s\n",
      "Iteration 70, Loss: 0.723101, T=238s, eta=609s\n",
      "Iteration 80, Loss: 1.055035, T=272s, eta=576s\n",
      "Iteration 90, Loss: 1.007991, T=306s, eta=542s\n",
      "Iteration 100, Loss: 1.147771, T=340s, eta=509s\n",
      "Iteration 110, Loss: 1.695535, T=375s, eta=476s\n",
      "Iteration 120, Loss: 1.546634, T=409s, eta=443s\n",
      "Iteration 130, Loss: 1.500587, T=443s, eta=409s\n",
      "Iteration 140, Loss: 1.857865, T=477s, eta=375s\n",
      "Iteration 150, Loss: 1.472231, T=511s, eta=342s\n",
      "Iteration 160, Loss: 2.462461, T=545s, eta=308s\n",
      "Iteration 170, Loss: 2.093630, T=579s, eta=274s\n",
      "Iteration 180, Loss: 1.545639, T=613s, eta=240s\n",
      "Iteration 190, Loss: 2.547595, T=647s, eta=206s\n",
      "Iteration 200, Loss: 2.031090, T=682s, eta=173s\n",
      "Iteration 210, Loss: 2.501371, T=716s, eta=139s\n",
      "Iteration 220, Loss: 2.742482, T=750s, eta=105s\n",
      "Iteration 230, Loss: 2.828192, T=784s, eta=71s\n",
      "Iteration 240, Loss: 2.745591, T=817s, eta=37s\n",
      "Iterations: 250\n",
      "Average fidelity over 5 timesteps: 0.73\n",
      "Fidelity across 10 timesteps: [1.         0.75307206 0.78865803 0.74860818 0.69591505 0.6625737\n",
      " 0.63545622 0.61818136 0.58743217 0.54756492 0.51893844]\n"
     ]
    }
   ],
   "source": [
    "# Train RNN\n",
    "result = optimize_pulse(\n",
    "    U_0=rho_target,\n",
    "    C_target=rho_target,\n",
    "    system_params=system_params,\n",
    "    num_time_steps=num_time_steps,\n",
    "    reward_weights=reward_weights,\n",
    "    mode=\"nn\",\n",
    "    goal=\"fidelity\",\n",
    "    max_iter=N_training_iterations,\n",
    "    convergence_threshold=convergence_threshold,\n",
    "    learning_rate=learning_rate,\n",
    "    evo_type=\"density\",\n",
    "    batch_size=batch_size,\n",
    "    eval_batch_size=eval_batch_size,\n",
    "    eval_time_steps=eval_time_steps,\n",
    "    progress=True,\n",
    "    rnn_hidden_size=rnn_hidden_size,\n",
    ")\n",
    "\n",
    "print(f\"Iterations: {result.iterations}\")\n",
    "print(f\"Average fidelity over 5 timesteps: {jnp.mean(jnp.mean(jnp.array(result.fidelity_each_timestep), axis=1)[1:6]):.2f}\")\n",
    "print(f\"Fidelity across {eval_time_steps} timesteps: \\n{jnp.mean(jnp.array(result.fidelity_each_timestep), axis=1)}\")\n",
    "\n",
    "# Expected output:\n",
    "# Iterations: 250\n",
    "# Average fidelity over 5 timesteps: 0.73\n",
    "# Fidelity across 10 timesteps:\n",
    "# [1.         0.75307206 0.78865803 0.74860818 0.69591505 0.6625737 0.63545622 0.61818136 0.58743217 0.54756492 0.51893844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b1a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity of uncontrolled dynamics across 10 timesteps: [1.         0.54488266 0.38306071 0.31783434 0.28817987 0.27384715\n",
      " 0.26740115 0.26570994 0.26725884 0.27118467 0.2769193 ]\n",
      "Avergage fidelity over first 5 timesteps: 0.36\n"
     ]
    }
   ],
   "source": [
    "# Simulation of the uncontrolled dynamics\n",
    "import dynamiqs as dq\n",
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "dq_result = dq.mesolve(\n",
    "    H=jnp.zeros((dim, dim)), # No Hamiltonian\n",
    "    jump_ops=jump_ops(N_qubits, gamma_z, gamma_m),\n",
    "    rho0=rho_target,\n",
    "    tsave=jnp.linspace(0, eval_time_steps, eval_time_steps + 1),\n",
    ")\n",
    "\n",
    "rho_t = dq_result.states.to_jax()\n",
    "fidelities = jnp.array([fidelity(C_target=rho_target, U_final=rho_ti, evo_type=\"density\") for rho_ti in rho_t])\n",
    "print(f\"Fidelity of uncontrolled dynamics across {eval_time_steps} timesteps: \\n{fidelities}\")\n",
    "print(f\"Avergage fidelity over first 5 timesteps: {jnp.mean(fidelities[1:6]):.2f}\")\n",
    "\n",
    "# Expected output: Fidelity of uncontrolled dynamics across 10 timesteps:\n",
    "# [1.         0.54488266 0.38306071 0.31783434 0.28817987 0.27384715 0.26740115 0.26570994 0.26725884 0.27118467 0.2769193 ]\n",
    "# Avergage fidelity over first 5 timesteps: 0.36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgrape_paper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
