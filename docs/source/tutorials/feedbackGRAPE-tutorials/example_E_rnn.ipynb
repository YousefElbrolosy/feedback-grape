{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16070338",
   "metadata": {},
   "source": [
    "# E: State stabilization with SNAP gates and displacement gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e400e",
   "metadata": {},
   "source": [
    "The use of feedback GRAPE applied to the Jaynes-\n",
    "Cummings scenario allows us to discover strategies\n",
    "extending the lifetime of a range of quantum states. How-\n",
    "ever, for more complex quantum states such as kitten\n",
    "states, the infidelity becomes significant after just a few\n",
    "dissipative evolution steps in spite of the feedback [cf.\n",
    "Fig. 6(c)]. This raises the question of whether the limited\n",
    "quality of the stabilization is to be attributed to a failure\n",
    "of our feedback-GRAPE learning algorithm to properly\n",
    "explore the control-parameter landscape or, rather, to the\n",
    "limited expressivity of the controls. With the goal of\n",
    "addressing this question, we test our method on the state-\n",
    "stabilization task using a more expressive control scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6003222d",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cea5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "from feedback_grape.fgrape import optimize_pulse\n",
    "from feedback_grape.utils.operators import cosm, sinm, identity\n",
    "from feedback_grape.utils.states import coherent\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851f72b",
   "metadata": {},
   "source": [
    "## Initialize states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa672e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.fidelity import ket2dm\n",
    "\n",
    "N_cav = 30  # number of cavity modes\n",
    "N_snap = 15\n",
    "\n",
    "alpha = 2\n",
    "psi_target = coherent(N_cav, alpha) + coherent(N_cav, -alpha)\n",
    "\n",
    "# Normalize psi_target before constructing rho_target\n",
    "psi_target = psi_target / jnp.linalg.norm(psi_target)\n",
    "\n",
    "rho_target = ket2dm(psi_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702387d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity Operator\n",
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def parity_operator(N_cav):\n",
    "    return jax.scipy.linalg.expm(1j * jnp.pi * (create(N_cav) @ destroy(N_cav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1b85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parity check for the kitten2 state: True\n",
      "parity_check trace : 1.0000000000000013\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the kitten2 state has an even parity\n",
    "parity_op = parity_operator(N_cav)\n",
    "parity_check = jnp.isclose(\n",
    "    jnp.trace((parity_op @ rho_target) @ rho_target), 1.0\n",
    ")\n",
    "print(\"Parity check for the kitten2 state:\", parity_check)\n",
    "print(\"parity_check trace :\", jnp.real(jnp.trace(parity_op @ rho_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eda36a",
   "metadata": {},
   "source": [
    "## Initialize the parameterized Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9381af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displacement_gate(alphas):\n",
    "    \"\"\"Displacement operator for a coherent state.\"\"\"\n",
    "    alpha_re, alpha_im = alphas\n",
    "    alpha = alpha_re + 1j * alpha_im\n",
    "    gate = jax.scipy.linalg.expm(\n",
    "        alpha * create(N_cav) - alpha.conj() * destroy(N_cav)\n",
    "    )\n",
    "    return gate\n",
    "\n",
    "\n",
    "def displacement_gate_dag(alphas):\n",
    "    \"\"\"Displacement operator for a coherent state.\"\"\"\n",
    "    alpha_re, alpha_im = alphas\n",
    "    alpha = alpha_re + 1j * alpha_im\n",
    "    gate = (\n",
    "        jax.scipy.linalg.expm(\n",
    "            alpha * create(N_cav) - alpha.conj() * destroy(N_cav)\n",
    "        )\n",
    "        .conj()\n",
    "        .T\n",
    "    )\n",
    "    return gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d692ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_gate(phase_list):\n",
    "    diags = jnp.ones(shape=(N_cav - len(phase_list)))\n",
    "    exponentiated = jnp.exp(1j * jnp.array(phase_list))\n",
    "    diags = jnp.concatenate((exponentiated, diags))\n",
    "    return jnp.diag(diags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029b826",
   "metadata": {},
   "source": [
    "### povm_measure_operator (callable): <br>\n",
    "    - It should take a measurement outcome and list of params as input\n",
    "    - The measurement outcome options are either 1 or -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a84b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def povm_measure_operator(measurement_outcome, params):\n",
    "    \"\"\"\n",
    "    POVM for the measurement of the cavity state.\n",
    "    returns Mm ( NOT the POVM element Em = Mm_dag @ Mm ), given measurement_outcome m, gamma and delta\n",
    "    \"\"\"\n",
    "    gamma, delta = params\n",
    "    angle = gamma * create(N_cav) @ destroy(N_cav) + delta / 2 * identity(N_cav)\n",
    "    meas_op = jnp.where(\n",
    "        measurement_outcome == 1,\n",
    "        cosm(angle),\n",
    "        sinm(angle),\n",
    "    )\n",
    "    return meas_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d72e6",
   "metadata": {},
   "source": [
    "## Initialize RNN of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83584086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "# You can do whatever you want inside so long as you maintaing the hidden_size and output size shapes\n",
    "class RNN(nn.Module):\n",
    "    hidden_size: int  # number of features in the hidden state\n",
    "    output_size: int  # number of features in the output (inferred from the number of parameters) just provide those attributes to the class\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, measurement, hidden_state):\n",
    "\n",
    "        if measurement.ndim == 1:\n",
    "            measurement = measurement.reshape(1, -1)\n",
    "\n",
    "        ###############\n",
    "        ### Free to change whatever you want below as long as hidden layers have size self.hidden_size\n",
    "        ### and output layer has size self.output_size\n",
    "        ###############\n",
    "\n",
    "        gru_cell = nn.GRUCell(\n",
    "            features=self.hidden_size,\n",
    "            gate_fn=nn.sigmoid,\n",
    "            activation_fn=nn.tanh,\n",
    "        )\n",
    "        self.make_rng('dropout')\n",
    "\n",
    "        new_hidden_state, _ = gru_cell(hidden_state, measurement)\n",
    "        new_hidden_state = nn.Dropout(rate=0.1, deterministic=False)(\n",
    "            new_hidden_state\n",
    "        )\n",
    "        # this returns the povm_params after linear regression through the hidden state which contains\n",
    "        # the information of the previous time steps and this is optimized to output best povm_params\n",
    "        # new_hidden_state = nn.Dense(features=self.hidden_size)(new_hidden_state)\n",
    "        new_hidden_state = nn.Dense(\n",
    "            features=self.hidden_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "        )(new_hidden_state)\n",
    "        new_hidden_state = nn.relu(new_hidden_state)\n",
    "        new_hidden_state = nn.Dense(\n",
    "            features=self.hidden_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "        )(new_hidden_state)\n",
    "        new_hidden_state = nn.relu(new_hidden_state)\n",
    "        output = nn.Dense(\n",
    "            features=self.output_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "            bias_init=nn.initializers.constant(0.1),\n",
    "        )(new_hidden_state)\n",
    "        output = nn.relu(output)\n",
    "\n",
    "        ###############\n",
    "        ### Do not change the return statement\n",
    "        ###############\n",
    "\n",
    "        return output[0], new_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846472f",
   "metadata": {},
   "source": [
    "### In this notebook, we decreased the convergence threshold and evaluate for num_time_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f91cd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward weights: (1, 1)\n",
      " fidelity@t=2: [0.89483129 0.8947372  0.91842732 0.90657416 0.8937841  0.89139012\n",
      " 0.9193737  0.92129226 0.89245941 0.89358357 0.91818892 0.91058352\n",
      " 0.89886416 0.8934184  0.91245221 0.91781651]\n",
      " fidelity_each_timestep: [1.00000002 0.95622085 0.90486105 0.8726336  0.8421597  0.81681455]\n",
      "\n",
      "reward weights: (0, 1)\n",
      " fidelity@t=2: [0.92087622 0.85413721 0.9208776  0.85423733 0.92087818 0.92087795\n",
      " 0.92087821 0.92087783 0.9208777  0.85418222 0.92087799 0.92087857\n",
      " 0.92087814 0.92087811 0.92087767 0.92087735]\n",
      " fidelity_each_timestep: [1.00000002 0.9429708  0.90837302 0.87654936 0.84724305 0.82022464]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note if tsave = jnp.linspace(0, 1, 1) = [0.0] then the decay is not applied ?\n",
    "# because the first time step has the original non decayed state\n",
    "from feedback_grape.fgrape import Decay, Gate\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Answer: In documentation, clarify that the initial_params are the params up to the\n",
    "# point where measurement occurs, compared with other modes where the initial_params\n",
    "# are the initial params for the entire system for all time steps. --> this is already fixed in\n",
    "# example a and an explanation of the mechanism may be provided in the docs\n",
    "measure = Gate(\n",
    "    gate=povm_measure_operator,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),  # 2 for gamma and delta\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=True,\n",
    ")\n",
    "\n",
    "displacement = Gate(\n",
    "    gate=displacement_gate,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "snap = Gate(\n",
    "    gate=snap_gate,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(N_snap,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "displacement_dag = Gate(\n",
    "    gate=displacement_gate_dag,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "decay = Decay(c_ops=[jnp.sqrt(0.005) * destroy(N_cav)])\n",
    "\n",
    "system_params = [decay, measure, decay, displacement, snap, displacement_dag]\n",
    "\n",
    "for reward_weights in [(1,1),(0,1)]:\n",
    "    result = optimize_pulse(\n",
    "        U_0=rho_target,\n",
    "        C_target=rho_target,\n",
    "        system_params=system_params,\n",
    "        num_time_steps=2,\n",
    "        lut_depth=1,\n",
    "        reward_weights=reward_weights,\n",
    "        mode=\"nn\",\n",
    "        goal=\"fidelity\",\n",
    "        max_iter=1000,\n",
    "        convergence_threshold=1e-6,\n",
    "        learning_rate=0.01,\n",
    "        evo_type=\"density\",\n",
    "        batch_size=16,\n",
    "        rnn=RNN,\n",
    "        rnn_hidden_size=30,\n",
    "        eval_batch_size=16,\n",
    "        eval_time_steps=5,\n",
    "    )\n",
    "\n",
    "    print(f\"reward weights: {reward_weights}\\n fidelity@t=2: {result.fidelity_each_timestep[2]}\\n fidelity_each_timestep: {jnp.mean(jnp.array(result.fidelity_each_timestep), axis=1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ee6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([1.00000002, 1.00000002, 1.00000002, 1.00000002, 1.00000002,\n",
       "        1.00000002, 1.00000002, 1.00000002, 1.00000002, 1.00000002,\n",
       "        1.00000002, 1.00000002, 1.00000002, 1.00000002, 1.00000002,\n",
       "        1.00000002], dtype=float64),\n",
       " Array([0.95697156, 0.88224816, 0.95697156, 0.88235741, 0.95697156,\n",
       "        0.95697156, 0.95697156, 0.95697156, 0.95697156, 0.882297  ,\n",
       "        0.95697156, 0.95697156, 0.95697156, 0.95697156, 0.95697156,\n",
       "        0.95697156], dtype=float64),\n",
       " Array([0.92087622, 0.85413721, 0.9208776 , 0.85423733, 0.92087818,\n",
       "        0.92087795, 0.92087821, 0.92087783, 0.9208777 , 0.85418222,\n",
       "        0.92087799, 0.92087857, 0.92087814, 0.92087811, 0.92087767,\n",
       "        0.92087735], dtype=float64),\n",
       " Array([0.88781776, 0.82766092, 0.88782115, 0.82775346, 0.88782236,\n",
       "        0.88782193, 0.88782154, 0.88782026, 0.88782022, 0.82770406,\n",
       "        0.88782078, 0.88782269, 0.88782043, 0.88782257, 0.88782132,\n",
       "        0.88781832], dtype=float64),\n",
       " Array([0.85750753, 0.80269906, 0.85751421, 0.80278665, 0.85751355,\n",
       "        0.85751346, 0.85751334, 0.85751055, 0.85751058, 0.80274073,\n",
       "        0.85751238, 0.8575166 , 0.85751062, 0.85751743, 0.85751337,\n",
       "        0.85750875], dtype=float64),\n",
       " Array([0.82968784, 0.77914787, 0.82969631, 0.77923091, 0.82969455,\n",
       "        0.82969673, 0.82969491, 0.82969035, 0.82969203, 0.77918764,\n",
       "        0.82969311, 0.82969995, 0.82969345, 0.82969934, 0.82969825,\n",
       "        0.82969101], dtype=float64)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.fidelity_each_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24452f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 30, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8321286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.fidelity import ket2dm\n",
    "\n",
    "N_cav = 30  # number of cavity modes\n",
    "N_snap = 15\n",
    "\n",
    "alpha = 2\n",
    "psi_target = coherent(N_cav, alpha) + coherent(N_cav, -alpha)\n",
    "\n",
    "# Normalize psi_target before constructing rho_target\n",
    "psi_target = psi_target / jnp.linalg.norm(psi_target)\n",
    "\n",
    "rho_target = ket2dm(psi_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712ec5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 1.0000000229244537\n",
      "fidelity of state 0: 0.8296878375980221\n",
      "fidelity of state 1: 0.7791478666667535\n",
      "fidelity of state 2: 0.8296963141742593\n",
      "fidelity of state 3: 0.7792309106394792\n",
      "fidelity of state 4: 0.8296945526856592\n",
      "fidelity of state 5: 0.8296967347225052\n",
      "fidelity of state 6: 0.8296949119658734\n",
      "fidelity of state 7: 0.8296903474907961\n",
      "fidelity of state 8: 0.8296920347565511\n",
      "fidelity of state 9: 0.7791876352174284\n",
      "fidelity of state 10: 0.8296931111890967\n",
      "fidelity of state 11: 0.8296999523450648\n",
      "fidelity of state 12: 0.829693454603234\n",
      "fidelity of state 13: 0.8296993417970175\n",
      "fidelity of state 14: 0.8296982466372378\n",
      "fidelity of state 15: 0.829691013696183\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho_target, evo_type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, evo_type=\"density\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
