{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16070338",
   "metadata": {},
   "source": [
    "# E: State stabilization with SNAP gates and displacement gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e400e",
   "metadata": {},
   "source": [
    "The use of feedback GRAPE applied to the Jaynes-\n",
    "Cummings scenario allows us to discover strategies\n",
    "extending the lifetime of a range of quantum states. How-\n",
    "ever, for more complex quantum states such as kitten\n",
    "states, the infidelity becomes significant after just a few\n",
    "dissipative evolution steps in spite of the feedback [cf.\n",
    "Fig. 6(c)]. This raises the question of whether the limited\n",
    "quality of the stabilization is to be attributed to a failure\n",
    "of our feedback-GRAPE learning algorithm to properly\n",
    "explore the control-parameter landscape or, rather, to the\n",
    "limited expressivity of the controls. With the goal of\n",
    "addressing this question, we test our method on the state-\n",
    "stabilization task using a more expressive control scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6003222d",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cea5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "from feedback_grape.fgrape import optimize_pulse\n",
    "from feedback_grape.utils.operators import sigmam, identity, cosm, sinm\n",
    "from feedback_grape.utils.states import coherent, basis\n",
    "from feedback_grape.utils.tensor import tensor\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax.scipy.linalg import expm\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851f72b",
   "metadata": {},
   "source": [
    "## Initialize states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa672e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.fidelity import ket2dm\n",
    "\n",
    "N_cav = 30  # number of cavity modes\n",
    "N_snap = 15\n",
    "\n",
    "alpha = 2\n",
    "psi_target = coherent(N_cav, alpha) + coherent(N_cav, -alpha)\n",
    "\n",
    "# Normalize psi_target before constructing rho_target\n",
    "psi_target = psi_target / jnp.linalg.norm(psi_target)\n",
    "\n",
    "rho_target = ket2dm(psi_target)\n",
    "\n",
    "rho_target = tensor(rho_target, ket2dm(basis(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702387d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity Operator\n",
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def parity_operator(N_cav):\n",
    "    return tensor(\n",
    "        jax.scipy.linalg.expm(1j * jnp.pi * (create(N_cav) @ destroy(N_cav))),\n",
    "        identity(2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1b85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parity check for the kitten2 state: True\n",
      "parity_check trace : 1.0000000000000013\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the kitten2 state has an even parity\n",
    "parity_op = parity_operator(N_cav)\n",
    "parity_check = jnp.isclose(\n",
    "    jnp.trace((parity_op @ rho_target) @ rho_target), 1.0\n",
    ")\n",
    "print(\"Parity check for the kitten2 state:\", parity_check)\n",
    "print(\"parity_check trace :\", jnp.real(jnp.trace(parity_op @ rho_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eda36a",
   "metadata": {},
   "source": [
    "## Initialize the parameterized Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9381af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displacement_gate(alphas):\n",
    "    \"\"\"Displacement operator for a coherent state.\"\"\"\n",
    "    alpha_re, alpha_im = alphas\n",
    "    alpha = alpha_re + 1j * alpha_im\n",
    "    gate = jax.scipy.linalg.expm(\n",
    "        alpha * create(N_cav) - alpha.conj() * destroy(N_cav)\n",
    "    )\n",
    "    return tensor(gate, identity(2))\n",
    "\n",
    "\n",
    "def displacement_gate_dag(alphas):\n",
    "    \"\"\"Displacement operator for a coherent state.\"\"\"\n",
    "    alpha_re, alpha_im = alphas\n",
    "    alpha = alpha_re + 1j * alpha_im\n",
    "    gate = (\n",
    "        jax.scipy.linalg.expm(\n",
    "            alpha * create(N_cav) - alpha.conj() * destroy(N_cav)\n",
    "        )\n",
    "        .conj()\n",
    "        .T\n",
    "    )\n",
    "    return tensor(gate, identity(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d692ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_gate(phase_list):\n",
    "    diags = jnp.ones(shape=(N_cav - len(phase_list)))\n",
    "    exponentiated = jnp.exp(1j * jnp.array(phase_list))\n",
    "    diags = jnp.concatenate((exponentiated, diags))\n",
    "    return tensor(jnp.diag(diags), identity(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5029b826",
   "metadata": {},
   "source": [
    "### povm_measure_operator (callable): <br>\n",
    "    - It should take a measurement outcome and list of params as input\n",
    "    - The measurement outcome options are either 1 or -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a84b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def povm_measure_operator(measurement_outcome, params):\n",
    "    \"\"\"\n",
    "    POVM for the measurement of the cavity state.\n",
    "    returns Mm ( NOT the POVM element Em = Mm_dag @ Mm ), given measurement_outcome m, gamma and delta\n",
    "    \"\"\"\n",
    "    gamma, delta = params\n",
    "    number_operator = tensor(create(N_cav) @ destroy(N_cav), identity(2))\n",
    "    angle = (gamma * number_operator) + delta / 2\n",
    "    meas_op = jnp.where(\n",
    "        measurement_outcome == 1,\n",
    "        cosm(angle),\n",
    "        sinm(angle),\n",
    "    )\n",
    "    return meas_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d72e6",
   "metadata": {},
   "source": [
    "## Initialize RNN of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83584086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "# You can do whatever you want inside so long as you maintaing the hidden_size and output size shapes\n",
    "class RNN(nn.Module):\n",
    "    hidden_size: int  # number of features in the hidden state\n",
    "    output_size: int  # number of features in the output (inferred from the number of parameters) just provide those attributes to the class\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, measurement, hidden_state):\n",
    "\n",
    "        if measurement.ndim == 1:\n",
    "            measurement = measurement.reshape(1, -1)\n",
    "\n",
    "        ###############\n",
    "        ### Free to change whatever you want below as long as hidden layers have size self.hidden_size\n",
    "        ### and output layer has size self.output_size\n",
    "        ###############\n",
    "\n",
    "        gru_cell = nn.GRUCell(\n",
    "            features=self.hidden_size,\n",
    "            gate_fn=nn.sigmoid,\n",
    "            activation_fn=nn.tanh,\n",
    "        )\n",
    "        self.make_rng('dropout')\n",
    "\n",
    "        new_hidden_state, _ = gru_cell(hidden_state, measurement)\n",
    "        new_hidden_state = nn.Dropout(rate=0.1, deterministic=False)(\n",
    "            new_hidden_state\n",
    "        )\n",
    "        # this returns the povm_params after linear regression through the hidden state which contains\n",
    "        # the information of the previous time steps and this is optimized to output best povm_params\n",
    "        # new_hidden_state = nn.Dense(features=self.hidden_size)(new_hidden_state)\n",
    "        new_hidden_state = nn.Dense(\n",
    "            features=self.hidden_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "        )(new_hidden_state)\n",
    "        new_hidden_state = nn.relu(new_hidden_state)\n",
    "        new_hidden_state = nn.Dense(\n",
    "            features=self.hidden_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "        )(new_hidden_state)\n",
    "        new_hidden_state = nn.relu(new_hidden_state)\n",
    "        output = nn.Dense(\n",
    "            features=self.output_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "            bias_init=nn.initializers.constant(0.1),\n",
    "        )(new_hidden_state)\n",
    "        output = nn.relu(output)\n",
    "\n",
    "        ###############\n",
    "        ### Do not change the return statement\n",
    "        ###############\n",
    "\n",
    "        return output[0], new_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846472f",
   "metadata": {},
   "source": [
    "### In this notebook, we decreased the convergence threshold and evaluate for num_time_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f91cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note if tsave = jnp.linspace(0, 1, 1) = [0.0] then the decay is not applied ?\n",
    "# because the first time step has the original non decayed state\n",
    "from feedback_grape.fgrape import Decay, Gate\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Answer: In documentation, clarify that the initial_params are the params up to the\n",
    "# point where measurement occurs, compared with other modes where the initial_params\n",
    "# are the initial params for the entire system for all time steps. --> this is already fixed in\n",
    "# example a and an explanation of the mechanism may be provided in the docs\n",
    "measure = Gate(\n",
    "    gate=povm_measure_operator,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),  # 2 for gamma and delta\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=True,\n",
    ")\n",
    "\n",
    "displacement = Gate(\n",
    "    gate=displacement_gate,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "snap = Gate(\n",
    "    gate=snap_gate,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(N_snap,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "displacement_dag = Gate(\n",
    "    gate=displacement_gate_dag,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key,\n",
    "        shape=(2,),\n",
    "        minval=-jnp.pi / 2,\n",
    "        maxval=jnp.pi / 2,\n",
    "        dtype=jnp.float64,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    ")\n",
    "\n",
    "decay = Decay(c_ops=[tensor(identity(N_cav), jnp.sqrt(0.005) * sigmam())])\n",
    "\n",
    "system_params = [decay, measure, decay, displacement, snap, displacement_dag]\n",
    "\n",
    "\n",
    "result = optimize_pulse(\n",
    "    U_0=rho_target,\n",
    "    C_target=rho_target,\n",
    "    system_params=system_params,\n",
    "    num_time_steps=2,\n",
    "    mode=\"nn\",\n",
    "    goal=\"fidelity\",\n",
    "    max_iter=1000,\n",
    "    convergence_threshold=1e-6,\n",
    "    learning_rate=0.01,\n",
    "    evo_type=\"density\",\n",
    "    batch_size=16,\n",
    "    rnn=RNN,\n",
    "    rnn_hidden_size=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403a1197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.98017231, dtype=float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24452f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8321286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.fidelity import ket2dm\n",
    "\n",
    "N_cav = 30  # number of cavity modes\n",
    "N_snap = 15\n",
    "\n",
    "alpha = 2\n",
    "psi_target = coherent(N_cav, alpha) + coherent(N_cav, -alpha)\n",
    "\n",
    "# Normalize psi_target before constructing rho_target\n",
    "psi_target = psi_target / jnp.linalg.norm(psi_target)\n",
    "\n",
    "rho_target = ket2dm(psi_target)\n",
    "\n",
    "rho_target = tensor(rho_target, ket2dm(basis(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712ec5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 1.0000000382238934\n",
      "fidelity of state 0: 0.9801980328535542\n",
      "fidelity of state 1: 0.980188088278855\n",
      "fidelity of state 2: 0.980186821220565\n",
      "fidelity of state 3: 0.9800495415969851\n",
      "fidelity of state 4: 0.9801779081992338\n",
      "fidelity of state 5: 0.9801961857038134\n",
      "fidelity of state 6: 0.9801947521631478\n",
      "fidelity of state 7: 0.9801954545468874\n",
      "fidelity of state 8: 0.98017357991852\n",
      "fidelity of state 9: 0.9801627309661755\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho_target, evo_type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, evo_type=\"density\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
