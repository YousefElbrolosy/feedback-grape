{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76d2ebd",
   "metadata": {},
   "source": [
    "# D. State stabilization in a noisy environment with Jaynes-Cummings controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018ebc9",
   "metadata": {},
   "source": [
    "Here the result is as follows: The algorithm optimizes the params, such that the POVM always outputs 1, implying that the measurement leaves the target state invariant. this is what we are indeed seeing when printing the measurement outcome and its probability, when batching however, the optimizer struggles to converge.\n",
    "\n",
    "Also, lookup here is much better than nn for the same hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d5142",
   "metadata": {},
   "source": [
    "This is actually a perfect example, of feedback grape modifying the params so that a certain measurement sequence will always be output because this measurement sequence is the one that is going to lead to the best fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408d7729",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.fgrape import optimize_pulse\n",
    "from feedback_grape.utils.operators import (\n",
    "    sigmap,\n",
    "    sigmam,\n",
    "    create,\n",
    "    destroy,\n",
    "    identity,\n",
    "    cosm,\n",
    "    sinm,\n",
    ")\n",
    "from feedback_grape.utils.states import basis\n",
    "from feedback_grape.utils.tensor import tensor\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4baf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cav = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9d984",
   "metadata": {},
   "source": [
    "## Here, dividing alpha into real and imaginary parts complicates the optimization and converges at 0.89 while if we do not use the imaginary part it converges at 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c912a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_unitary(alphas):\n",
    "    alpha_re, alpha_im = alphas\n",
    "    alpha = alpha_re + 1j * alpha_im\n",
    "    return tensor(\n",
    "        identity(N_cav),\n",
    "        expm(-1j * (alpha * sigmap() + alpha.conjugate() * sigmam()) / 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1baa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_cavity_unitary(betas):\n",
    "    beta_re, beta_im = betas\n",
    "    beta = beta_re + 1j * beta_im\n",
    "    return expm(\n",
    "        -1j\n",
    "        * (\n",
    "            beta * (tensor(destroy(N_cav), sigmap()))\n",
    "            + beta.conjugate() * (tensor(create(N_cav), sigmam()))\n",
    "        )\n",
    "        / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18095d1e",
   "metadata": {},
   "source": [
    "### povm_measure_operator (callable): <br>\n",
    "    - It should take a measurement outcome and list of params as input\n",
    "    - The measurement outcome options are either 1 or -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a6a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def povm_measure_operator(measurement_outcome, params):\n",
    "    \"\"\"\n",
    "    POVM for the measurement of the cavity state.\n",
    "    returns Mm ( NOT the POVM element Em = Mm_dag @ Mm ), given measurement_outcome m, gamma and delta\n",
    "    \"\"\"\n",
    "    gamma, delta = params\n",
    "    number_operator = tensor(create(N_cav) @ destroy(N_cav), identity(2))\n",
    "    angle = (gamma * number_operator) + delta / 2 * identity(2*N_cav)\n",
    "    meas_op = jnp.where(\n",
    "        measurement_outcome == 1,\n",
    "        cosm(angle),\n",
    "        sinm(angle),\n",
    "    )\n",
    "    return meas_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce889fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.states import coherent\n",
    "\n",
    "alpha = 3\n",
    "psi_target = tensor(\n",
    "    coherent(N_cav, alpha)\n",
    "    + coherent(N_cav, -alpha)\n",
    "    + coherent(N_cav, 1j * alpha)\n",
    "    + coherent(N_cav, -1j * alpha),\n",
    "    basis(2),\n",
    ")  # 4-legged state\n",
    "\n",
    "# Normalize psi_target before constructing rho_target\n",
    "psi_target = psi_target / jnp.linalg.norm(psi_target)\n",
    "rho_target = psi_target @ psi_target.conj().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2321d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bfc6e",
   "metadata": {},
   "source": [
    "### It is important to test what the POVM probability is, to check if your state is normalized. if the probability is bounded between 0 and 1 then normalized\n",
    "This completeness condition on the measurement operators is automatically checked for the `initial_params` in `optimize_pulse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6599acde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.09357621, dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer: should one normalize within the optimization just in case?\n",
    "# --> no so that user is not misled into thinking that his unnormalized state\n",
    "# is working properly\n",
    "from feedback_grape.utils.povm import (\n",
    "    _probability_of_a_measurement_outcome_given_a_certain_state,\n",
    ")\n",
    "\n",
    "_probability_of_a_measurement_outcome_given_a_certain_state(\n",
    "    rho_target,\n",
    "    +1,\n",
    "    povm_measure_operator(+1, params=[0.058, jnp.pi / 2]),\n",
    "    povm_measure_operator(-1, params=[0.058, jnp.pi / 2]),\n",
    "    evo_type=\"density\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6439b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(fidelity(U_final=rho_target, C_target=rho_target, evo_type=\"density\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2b30f",
   "metadata": {},
   "source": [
    "### Without dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_weights: (1, 1)\n",
      " fidelity@t=2: [0.61147643 0.61147643 0.61147643 0.61147643 0.61147643 0.61147643\n",
      " 0.61147643 0.61147643 0.61147643 0.61147643]\n",
      " mean fidelity each timestep: [1.         0.05440354 0.61147643 0.02560076 0.23348661 0.14675473]\n",
      "\n",
      "reward_weights: (0, 1)\n",
      " fidelity@t=2: [0.70072227 0.70072227 0.70072227 0.70072227 0.70072227 0.70072227\n",
      " 0.70072227 0.70072227 0.70072227 0.70072227]\n",
      " mean fidelity each timestep: [1.         0.10651565 0.70072227 0.08212367 0.15468819 0.26903952]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here the loss directly corressponds to the -fidelity (when converging) because log(1) is 0 and\n",
    "# the algorithm is choosing params that makes the POVM generate prob = 1\n",
    "from feedback_grape.fgrape import Gate, Decay\n",
    "import jax\n",
    "\n",
    "key1, key2, key3 = jax.random.split(jax.random.PRNGKey(42), 3)\n",
    "measure = Gate(\n",
    "    gate=povm_measure_operator,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key1,\n",
    "        shape=(2,),  # 2 for gamma and delta\n",
    "        minval=-2 * jnp.pi,\n",
    "        maxval=2 * jnp.pi,\n",
    "    ),\n",
    "    measurement_flag=True,\n",
    "    # param_constraints=[[0, jnp.pi], [-2*jnp.pi, 2*jnp.pi]],\n",
    ")\n",
    "\n",
    "qub_unitary = Gate(\n",
    "    gate=qubit_unitary,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key2,\n",
    "        shape=(2,),  # 2 for real(alpha) and imag(alpha)\n",
    "        minval=-2 * jnp.pi,\n",
    "        maxval=2 * jnp.pi,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    "    # param_constraints=[[-2*jnp.pi, 2*jnp.pi], [-2*jnp.pi, 2*jnp.pi]],\n",
    ")\n",
    "\n",
    "qub_cav = Gate(\n",
    "    gate=qubit_cavity_unitary,\n",
    "    initial_params=jax.random.uniform(\n",
    "        key3,\n",
    "        shape=(2,),  # 2 for real(beta) and imag(beta)\n",
    "        minval=-2 * jnp.pi,\n",
    "        maxval=2 * jnp.pi,\n",
    "    ),\n",
    "    measurement_flag=False,\n",
    "    # param_constraints=[[-jnp.pi, jnp.pi], [-jnp.pi, jnp.pi]],\n",
    ")\n",
    "\n",
    "system_params = [measure, qub_unitary, qub_cav]\n",
    "\n",
    "for reward_weights in [(1,1), (0,1)]:\n",
    "    result = optimize_pulse(\n",
    "        U_0=rho_target,\n",
    "        C_target=rho_target,\n",
    "        system_params=system_params,\n",
    "        num_time_steps=2,\n",
    "        reward_weights=reward_weights,\n",
    "        mode=\"lookup\",\n",
    "        goal=\"fidelity\",\n",
    "        max_iter=1000,\n",
    "        convergence_threshold=1e-6,\n",
    "        learning_rate=0.001,\n",
    "        evo_type=\"density\",\n",
    "        batch_size=1,\n",
    "        eval_time_steps=5,\n",
    "    )\n",
    "\n",
    "    print(f\"reward_weights: {reward_weights}\\n fidelity@t=2: {result.fidelity_each_timestep[2]}\\n mean fidelity each timestep: {jnp.mean(jnp.array(result.fidelity_each_timestep), axis=1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f410e7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([-3.25968973, -1.22546366], dtype=float64),\n",
       " Array([3.04255722, 0.59257698], dtype=float64),\n",
       " Array([-1.58503058,  2.06652483], dtype=float64)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.optimized_trainable_parameters[\"initial_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d6f7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Array([[-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366],\n",
       "         [-3.25968973, -1.22546366]], dtype=float64),\n",
       "  Array([[3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519],\n",
       "         [3.74446264, 1.05778519]], dtype=float64),\n",
       "  Array([[-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978],\n",
       "         [-1.18880838,  1.68717978]], dtype=float64)],\n",
       " [Array([[-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ],\n",
       "         [-3.21629637, -1.2256032 ]], dtype=float64),\n",
       "  Array([[2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018]], dtype=float64),\n",
       "  Array([[-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[2.84271624, 0.40064934],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.84271624, 0.40064934],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.84271624, 0.40064934],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.84271624, 0.40064934]], dtype=float64),\n",
       "  Array([[-1.46674406,  1.94780958],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46674406,  1.94780958],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46674406,  1.94780958],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46674406,  1.94780958]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[3.01885209, 0.5692014 ],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.9808619 , 0.53355941],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.9808619 , 0.53355941],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [3.01885209, 0.5692014 ]], dtype=float64),\n",
       "  Array([[-1.46156521,  1.94257903],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.50087405,  1.98214669],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.50087405,  1.98214669],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46156521,  1.94257903]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[3.01885209, 0.5692014 ],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.84271624, 0.40064934],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [2.36673839, 0.35245018],\n",
       "         [3.01885209, 0.5692014 ]], dtype=float64),\n",
       "  Array([[-1.46156521,  1.94257903],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46674406,  1.94780958],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.21602644,  1.68343375],\n",
       "         [-1.46156521,  1.94257903]], dtype=float64)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.returned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546d79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 1.0\n",
      "fidelity of state 0: 0.008146989341838724\n",
      "fidelity of state 1: 0.4296580047885219\n",
      "fidelity of state 2: 0.4296580047885219\n",
      "fidelity of state 3: 0.019468980947527772\n",
      "fidelity of state 4: 0.4296580047885219\n",
      "fidelity of state 5: 0.07668419535038538\n",
      "fidelity of state 6: 0.4296580047885219\n",
      "fidelity of state 7: 0.4296580047885219\n",
      "fidelity of state 8: 0.4296580047885219\n",
      "fidelity of state 9: 0.008146989341838724\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho_target, evo_type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, evo_type=\"density\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2190e32",
   "metadata": {},
   "source": [
    "### With Dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eec5fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_weights: (1, 1)\n",
      " fidelity@t=2: [0.55096597 0.55096597 0.55096597 0.05109454 0.55096597 0.55096597\n",
      " 0.55096597 0.55096597 0.55096597 0.55096597]\n",
      " mean fidelity each timestep: [1.         0.09291582 0.50097883 0.06732321 0.18326516 0.08771339]\n",
      "\n",
      "reward_weights: (0, 1)\n",
      " fidelity@t=2: [0.60162457 0.60162457 0.60162457 0.60162457 0.60162457 0.60162457\n",
      " 0.60162457 0.60162457 0.60162457 0.60162457]\n",
      " mean fidelity each timestep: [1.         0.10592718 0.60162457 0.08587846 0.16084106 0.11607979]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note if tsave = jnp.linspace(0, 1, 1) = [0.0] then the decay is not applied ?\n",
    "# because the first time step has the original non decayed state\n",
    "# Question: Here I should not use any sort of Hamiltonian or tspan or something?\n",
    "\n",
    "decay = Decay(\n",
    "    c_ops=[tensor(identity(N_cav), jnp.sqrt(0.1) * sigmam())],\n",
    ")\n",
    "system_params = [decay, measure, qub_unitary, qub_cav]\n",
    "\n",
    "for reward_weights in [(1,1), (0,1)]:\n",
    "    result = optimize_pulse(\n",
    "        U_0=rho_target,\n",
    "        C_target=rho_target,\n",
    "        system_params=system_params,\n",
    "        num_time_steps=2,\n",
    "        reward_weights=reward_weights,\n",
    "        mode=\"lookup\",\n",
    "        goal=\"fidelity\",\n",
    "        max_iter=1000,\n",
    "        convergence_threshold=1e-6,\n",
    "        learning_rate=0.001,\n",
    "        evo_type=\"density\",\n",
    "        batch_size=1,\n",
    "        eval_time_steps=5,\n",
    "    )\n",
    "\n",
    "    print(f\"reward_weights: {reward_weights}\\n fidelity@t=2: {result.fidelity_each_timestep[2]}\\n mean fidelity each timestep: {jnp.mean(jnp.array(result.fidelity_each_timestep), axis=1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bb8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 1.0\n",
      "fidelity of state 0: 0.15125949286446827\n",
      "fidelity of state 1: 0.013853869884188937\n",
      "fidelity of state 2: 0.013853869884188937\n",
      "fidelity of state 3: 0.24132876335064737\n",
      "fidelity of state 4: 0.24132876335064737\n",
      "fidelity of state 5: 0.013853869884188937\n",
      "fidelity of state 6: 0.24132876335064737\n",
      "fidelity of state 7: 0.03411857686442019\n",
      "fidelity of state 8: 0.09974453405941826\n",
      "fidelity of state 9: 0.11012737621612621\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho_target, evo_type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, evo_type=\"density\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c5f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Array([[-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491],\n",
       "         [-3.22390513, -1.25310491]], dtype=float64),\n",
       "  Array([[3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396],\n",
       "         [3.46904782, 1.00731396]], dtype=float64),\n",
       "  Array([[-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133],\n",
       "         [-1.23277087,  1.70909133]], dtype=float64)],\n",
       " [Array([[-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317],\n",
       "         [-3.20758943, -1.23624317]], dtype=float64),\n",
       "  Array([[2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342]], dtype=float64),\n",
       "  Array([[-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[2.64404879, 0.34142342],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.87954073, 0.43466602]], dtype=float64),\n",
       "  Array([[-1.19576575,  1.67196856],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.44127156,  1.92218951]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[2.64404879, 0.34142342],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.9525867 , 0.50673278],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.9525867 , 0.50673278]], dtype=float64),\n",
       "  Array([[-1.19576575,  1.67196856],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.46898634,  1.95006697],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.46898634,  1.95006697]], dtype=float64)],\n",
       " [Array([[-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487],\n",
       "         [-3.32166965, -1.29192487]], dtype=float64),\n",
       "  Array([[2.87954073, 0.43466602],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.90764869, 0.46205033],\n",
       "         [2.64404879, 0.34142342],\n",
       "         [2.87954073, 0.43466602],\n",
       "         [2.9525867 , 0.50673278],\n",
       "         [2.64404879, 0.34142342]], dtype=float64),\n",
       "  Array([[-1.44127156,  1.92218951],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.4670872 ,  1.94815557],\n",
       "         [-1.19576575,  1.67196856],\n",
       "         [-1.44127156,  1.92218951],\n",
       "         [-1.46898634,  1.95006697],\n",
       "         [-1.19576575,  1.67196856]], dtype=float64)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.returned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4441f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([-3.22390513, -1.25310491], dtype=float64),\n",
       " Array([3.04255722, 0.59257698], dtype=float64),\n",
       " Array([-1.58503058,  2.06652483], dtype=float64)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.optimized_trainable_parameters[\"initial_params\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
