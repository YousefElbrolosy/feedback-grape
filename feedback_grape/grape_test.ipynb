{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "\n",
    "\"\"\"\n",
    "Gradient Ascent Pulse Engineering (GRAPE)\n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from utils.gates import cnot\n",
    "from utils.operators import identity, sigmax, sigmay, sigmaz\n",
    "from utils.tensor import tensor\n",
    "\n",
    "# TODO: Implement this with Pavlo's Cavity + Qubit coupled in dispersive regime\n",
    "\n",
    "\n",
    "# for unitary evolution (not using density operator)\n",
    "def optimize_pulse(\n",
    "    H_drift,\n",
    "    H_control,\n",
    "    rho_0,\n",
    "    C_target,\n",
    "    num_t_slots,\n",
    "    total_evo_time,\n",
    "    max_iter=1000,\n",
    "    convergence_threshold=1e-6,\n",
    "    learning_rate=0.01,\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses GRAPE to optimize a pulse.\n",
    "    Args:\n",
    "        H_drift: Drift Hamiltonian.\n",
    "        H_control: List of Control Hamiltonians.\n",
    "        rho_0: Initial density operator.\n",
    "        C_target: Target operator.\n",
    "        num_t_slots: Number of time slots.\n",
    "        total_evo_time: Total evolution time.\n",
    "        max_iter: Maximum number of iterations.\n",
    "        convergence_threshold: Convergence threshold for fidelity change.\n",
    "        learning_rate: Learning rate for gradient ascent.\n",
    "    Returns:\n",
    "        result: Dictionary containing optimized pulse and convergence data.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize control amplitudes\n",
    "    control_amplitudes = init_control_amplitudes(num_t_slots, len(H_control))\n",
    "    delta_t = total_evo_time / num_t_slots\n",
    "\n",
    "    # Convert H_control to array for easier manipulation\n",
    "    H_control_array = jnp.array(H_control)\n",
    "\n",
    "    def fidelity(control_amplitudes):\n",
    "        propagators = compute_propagators(\n",
    "            H_drift, H_control_array, delta_t, control_amplitudes\n",
    "        )\n",
    "        U_final = compute_forward_evolution(\n",
    "            propagators, rho_0\n",
    "        )  # rho_0 is U_0 here\n",
    "        overlap = (\n",
    "            jnp.trace(jnp.matmul(C_target.conj().T, U_final))\n",
    "            / C_target.shape[0]\n",
    "        )\n",
    "        return (\n",
    "            jnp.abs(overlap) ** 2\n",
    "        )  # Fidelity = |Tr(U_target† U_final) / dim|^2\n",
    "\n",
    "    # Step 2: Gradient ascent loop\n",
    "    control_amplitudes, fidelities, iter_idx = optimize(\n",
    "        fidelity,\n",
    "        control_amplitudes,\n",
    "        max_iter,\n",
    "        learning_rate,\n",
    "        convergence_threshold,\n",
    "    )\n",
    "\n",
    "    propagators = compute_propagators(\n",
    "        H_drift, H_control_array, delta_t, control_amplitudes\n",
    "    )\n",
    "    rho_final = compute_forward_evolution(propagators, rho_0)\n",
    "\n",
    "    return {\n",
    "        \"control_amplitudes\": control_amplitudes,\n",
    "        \"final_fidelity\": fidelities[-1],\n",
    "        \"fidelity_history\": jnp.array(fidelities),\n",
    "        \"iterations\": iter_idx + 1,\n",
    "        \"final_density_operator\": rho_final,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_propagators(H_drift, H_control_array, delta_t, control_amplitudes):\n",
    "    \"\"\"\n",
    "    Compute propagators for each time step according to Equation (4).\n",
    "    Args:\n",
    "        H_drift: Drift Hamiltonian.\n",
    "        H_control_array: Array of control Hamiltonians.\n",
    "        delta_t: Time step for evolution.\n",
    "        control_amplitudes: Control amplitudes for each time slot.\n",
    "    Returns:\n",
    "        propagators: Array of propagators for each time step.\n",
    "    \"\"\"\n",
    "    num_t_slots = control_amplitudes.shape[0]\n",
    "\n",
    "    # Compute each Uj according to Equation (4)\n",
    "    def compute_propagator_j(j):\n",
    "        # Calculate total Hamiltonian for time step j\n",
    "        H_0 = H_drift\n",
    "        H_control = 0\n",
    "        for k in range(len(H_control_array)):\n",
    "            # print(f\"Control Hamiltonian \\n {H_control_array[k].real}\")\n",
    "            H_control += control_amplitudes[j, k] * H_control_array[k]\n",
    "\n",
    "        H_total = H_0 + H_control\n",
    "        # Compute propagator using matrix exponential (Equation 4)\n",
    "        U_j = jax.scipy.linalg.expm(-1j * delta_t * H_total)\n",
    "        return U_j\n",
    "\n",
    "    # Create an array of propagators\n",
    "    propagators = jax.vmap(compute_propagator_j)(jnp.arange(num_t_slots))\n",
    "    return propagators\n",
    "\n",
    "\n",
    "def compute_forward_evolution(propagators, U_0):\n",
    "    \"\"\"\n",
    "    Compute the forward evolution states (ρⱼ) according to the paper's definition.\n",
    "    ρⱼ = Uⱼ···U₁ρ₀U₁†···Uⱼ†\n",
    "\n",
    "    Args:\n",
    "        propagators: List of propagators for each time step.\n",
    "        rho_0: Initial density operator.\n",
    "    Returns:\n",
    "        rho_j: List of density operators for each time step j.\n",
    "    \"\"\"\n",
    "\n",
    "    U_final = U_0\n",
    "    for U_j in propagators:\n",
    "        # Forward evolution\n",
    "        # rho_final = U_j @ rho_final @ U_j.conj().T\n",
    "        U_final = U_j @ U_final\n",
    "\n",
    "    return U_final\n",
    "\n",
    "\n",
    "def init_control_amplitudes(num_t_slots, num_controls):\n",
    "    \"\"\"\n",
    "    Initialize control amplitudes for the optimization process.\n",
    "    Args:\n",
    "        num_t_slots: Number of time slots.\n",
    "        num_controls: Number of control Hamiltonians.\n",
    "    Returns:\n",
    "        init_control_amplitudes: Initialized control amplitudes.\n",
    "    \"\"\"\n",
    "    # Random initialization\n",
    "    # You can also initialize with zeros\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    return jax.random.uniform(\n",
    "        key,\n",
    "        (num_t_slots, num_controls),\n",
    "        minval=-(2 * jnp.pi * 0.05),\n",
    "        maxval=(2 * jnp.pi * 0.05),\n",
    "    )\n",
    "\n",
    "\n",
    "def optimize(\n",
    "    fidelity,\n",
    "    control_amplitudes,\n",
    "    max_iter,\n",
    "    learning_rate,\n",
    "    convergence_threshold,\n",
    "):\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(control_amplitudes)\n",
    "    fidelities = []\n",
    "\n",
    "    @jax.jit\n",
    "    def step(params, state):\n",
    "        loss = -fidelity(params)  # Minimize -fidelity\n",
    "        grads = jax.grad(lambda x: -fidelity(x))(params)\n",
    "        updates, new_state = optimizer.update(grads, state, params)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_state, -loss\n",
    "\n",
    "    params = control_amplitudes\n",
    "    for iter_idx in range(max_iter):\n",
    "        params, opt_state, current_fidelity = step(params, opt_state)\n",
    "        fidelities.append(current_fidelity)\n",
    "\n",
    "        if (\n",
    "            iter_idx > 0\n",
    "            and abs(fidelities[-1] - fidelities[-2]) < convergence_threshold\n",
    "        ):\n",
    "            print(f\"Converged after {iter_idx} iterations.\")\n",
    "            break\n",
    "\n",
    "        if iter_idx % 10 == 0:\n",
    "            print(f\"Iteration {iter_idx}, Fidelity: {current_fidelity}\")\n",
    "\n",
    "    return params, fidelities, iter_idx\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    g = 0  # Small coupling strength\n",
    "    H_drift = g * (tensor(sigmax(), sigmax()) + tensor(sigmay(), sigmay()))\n",
    "    H_ctrl = [\n",
    "        tensor(sigmax(), identity(2)),\n",
    "        tensor(sigmay(), identity(2)),\n",
    "        tensor(sigmaz(), identity(2)),\n",
    "        tensor(identity(2), sigmax()),\n",
    "        tensor(identity(2), sigmay()),\n",
    "        tensor(identity(2), sigmaz()),\n",
    "        tensor(sigmax(), sigmax()),\n",
    "        tensor(sigmay(), sigmay()),\n",
    "        tensor(sigmaz(), sigmaz()),\n",
    "    ]\n",
    "\n",
    "    U_0 = identity(4)\n",
    "    # Target operator (CNOT gate)\n",
    "    C_target = cnot()\n",
    "\n",
    "    num_t_slots = 500\n",
    "    total_evo_time = 2 * jnp.pi\n",
    "\n",
    "    # Run optimization\n",
    "    result = optimize_pulse(\n",
    "        H_drift,\n",
    "        H_ctrl,\n",
    "        U_0,\n",
    "        C_target,\n",
    "        num_t_slots,\n",
    "        total_evo_time,\n",
    "        max_iter=500,\n",
    "        learning_rate=1e-2,\n",
    "    )\n",
    "    print(\"final_fidelity: \", result[\"final_fidelity\"])\n",
    "    print(\"U_f \\n\", result[\"final_density_operator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_control_amplitudes(times, final_amps, labels):\n",
    "    num_controls = final_amps.shape[1]\n",
    "\n",
    "    y_max = 0.1  # Fixed y-axis scale\n",
    "    y_min = -0.1\n",
    "\n",
    "    for i in range(num_controls):\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "        for j in range(num_controls):\n",
    "            color = (\n",
    "                'black' if i == j else 'gray'\n",
    "            )  # Highlight the current control\n",
    "            alpha = 1.0 if i == j else 0.1\n",
    "            ax.plot(\n",
    "                times,\n",
    "                final_amps[:, j],\n",
    "                label=labels[j],\n",
    "                color=color,\n",
    "                alpha=alpha,\n",
    "            )\n",
    "        ax.set_title(f\"Control Fields Highlighting: {labels[i]}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(labels[i])\n",
    "        ax.set_ylim(y_min, y_max)  # Set fixed y-axis limits\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "times = jnp.linspace(0, 2 * jnp.pi, 500)\n",
    "H_labels = [\n",
    "    r'$u_{1x}$',\n",
    "    r'$u_{1y}$',\n",
    "    r'$u_{1z}$',\n",
    "    r'$u_{2x}$',\n",
    "    r'$u_{2y}$',\n",
    "    r'$u_{2z}$',\n",
    "    r'$u_{xx}$',\n",
    "    r'$u_{yy}$',\n",
    "    r'$u_{zz}$',\n",
    "]\n",
    "plot_control_amplitudes(\n",
    "    times, result[\"control_amplitudes\"] / (2 * jnp.pi), H_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_target = cnot()\n",
    "U_f = result[\"final_density_operator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(U_target, U_f):\n",
    "    \"\"\"\n",
    "    Calculate the overlap between the target unitary U_target and the final unitary U_f.\n",
    "\n",
    "    Parameters:\n",
    "    U_target (qutip.Qobj): Target unitary operator.\n",
    "    U_f (qutip.Qobj): Final unitary operator.\n",
    "\n",
    "    Returns:\n",
    "    float: Real part of the overlap value.\n",
    "    float: Fidelity (absolute square of the overlap).\n",
    "    \"\"\"\n",
    "    # dividing over U_target.shape[0] is for normalization\n",
    "    overlap_value = (\n",
    "        jnp.trace(jnp.matmul(U_target.conj().T, U_f)) / U_target.shape[0]\n",
    "    )\n",
    "    fidelity = abs(overlap_value) ** 2\n",
    "    return overlap_value.real, fidelity\n",
    "\n",
    "\n",
    "# Example usage\n",
    "overlap_real, fidelity = overlap(U_target, U_f)\n",
    "print(f\"Overlap (real part): {overlap_real}\")\n",
    "print(f\"Fidelity: {fidelity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPE with time-dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient Ascent Pulse Engineering (GRAPE)\n",
    "\"\"\"\n",
    "\n",
    "# ruff: noqa N8\n",
    "import jax\n",
    "import optax  # type: ignore\n",
    "import optax.tree_utils as otu\n",
    "from typing import NamedTuple\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# TODO: Implement this with Pavlo's Cavity + Qubit coupled in dispersive regime\n",
    "# TODO: remove side effects\n",
    "# TODO: implement optimizer same as qutip_qtrl fmin_lbfgs or sth\n",
    "\n",
    "\n",
    "class result(NamedTuple):\n",
    "    control_amplitudes: jnp.ndarray\n",
    "    final_fidelity: float\n",
    "    iterations: int\n",
    "    final_operator: jnp.ndarray\n",
    "\n",
    "\n",
    "def _compute_propagators(\n",
    "    H_drift,\n",
    "    H_control_array,\n",
    "    delta_t,\n",
    "    control_amplitudes,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute propagators for each time step according to Equation (4).\n",
    "    Args:\n",
    "        H_drift: Drift Hamiltonian.\n",
    "        H_control_array: Array of control Hamiltonians.\n",
    "        delta_t: Time step for evolution.\n",
    "        control_amplitudes: Control amplitudes for each time slot.\n",
    "    Returns:\n",
    "        propagators: Array of propagators for each time step.\n",
    "    \"\"\"\n",
    "    num_t_slots = control_amplitudes.shape[0]\n",
    "\n",
    "    # Compute each Uj according to Equation\n",
    "    def compute_propagator_j(j):\n",
    "        # Calculate total Hamiltonian for time step j\n",
    "        H_0 = H_drift\n",
    "        H_control = 0\n",
    "        for k in range(len(H_control_array)):\n",
    "            H_control += control_amplitudes[j, k] * H_control_array[k]\n",
    "\n",
    "        H_total = H_0 + H_control\n",
    "\n",
    "        U_j = jax.scipy.linalg.expm(-1j * delta_t * H_total)\n",
    "        return U_j\n",
    "\n",
    "    # Create an array of propagators\n",
    "    propagators = jax.vmap(compute_propagator_j)(jnp.arange(num_t_slots))\n",
    "    return propagators\n",
    "\n",
    "\n",
    "def _compute_forward_evolution(propagators, U_0):\n",
    "    \"\"\"\n",
    "    Compute the forward evolution states (ρⱼ) according to the paper's definition.\n",
    "    ρⱼ = Uⱼ···U₁ρ₀U₁†···Uⱼ†\n",
    "\n",
    "    Args:\n",
    "        propagators: List of propagators for each time step.\n",
    "        U_0: Initial density operator.\n",
    "    Returns:\n",
    "        rho_j: List of density operators for each time step j.\n",
    "    \"\"\"\n",
    "\n",
    "    U_final = U_0\n",
    "    for U_j in propagators:\n",
    "        # Forward evolution\n",
    "        # Use below if density operator is used\n",
    "        # rho_final = U_j @ rho_final @ U_j.conj().T\n",
    "        U_final = U_j @ U_final\n",
    "\n",
    "    return U_final\n",
    "\n",
    "\n",
    "def _init_control_amplitudes(num_t_slots, num_controls):\n",
    "    \"\"\"\n",
    "    Initialize control amplitudes for the optimization process.\n",
    "    Args:\n",
    "        num_t_slots: Number of time slots.\n",
    "        num_controls: Number of control Hamiltonians.\n",
    "    Returns:\n",
    "        init_control_amplitudes: Initialized control amplitudes.\n",
    "    \"\"\"\n",
    "    # Random initialization\n",
    "    # Here, you can't initialize with zeros, as it will lead to zero gradients\n",
    "    # and no updates. Instead, use a small random value. (perhaps because of adam, but\n",
    "    # TODO: use FMIN_L_BFGS_B instead of adam)\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    return jax.random.uniform(\n",
    "        key,\n",
    "        (num_t_slots, num_controls),\n",
    "        minval=-(2 * jnp.pi * 0.05),\n",
    "        maxval=(2 * jnp.pi * 0.05),\n",
    "    )\n",
    "\n",
    "\n",
    "def _optimize_adam(\n",
    "    _fidelity,\n",
    "    control_amplitudes,\n",
    "    max_iter,\n",
    "    learning_rate,\n",
    "    convergence_threshold,\n",
    "):\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(control_amplitudes)\n",
    "    fidelities = []\n",
    "\n",
    "    @jax.jit\n",
    "    def step(params, state):\n",
    "        loss = -_fidelity(params)  # Minimize -_fidelity\n",
    "        grads = jax.grad(lambda x: -_fidelity(x))(params)\n",
    "        updates, new_state = optimizer.update(grads, state, params)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_state, -loss\n",
    "\n",
    "    params = control_amplitudes\n",
    "    for iter_idx in range(max_iter):\n",
    "        params, opt_state, current_fidelity = step(params, opt_state)\n",
    "        fidelities.append(current_fidelity)\n",
    "\n",
    "        if (\n",
    "            iter_idx > 0\n",
    "            and abs(fidelities[-1] - fidelities[-2]) < convergence_threshold\n",
    "        ):\n",
    "            print(f\"Converged after {iter_idx} iterations.\")\n",
    "            break\n",
    "\n",
    "        if iter_idx % 10 == 0:\n",
    "            print(f\"Iteration {iter_idx}, _fidelity: {current_fidelity}\")\n",
    "    final_fidelity = fidelities[-1]\n",
    "    return params, final_fidelity, iter_idx\n",
    "\n",
    "\n",
    "def _optimize_L_BFGS(\n",
    "    _fidelity,\n",
    "    control_amplitudes,\n",
    "    max_iter,\n",
    "    convergence_threshold,\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses L-BFGS to optimize the control amplitudes.\n",
    "    Args:\n",
    "        _fidelity: Function to compute fidelity.\n",
    "        control_amplitudes: Initial control amplitudes.\n",
    "        max_iter: Maximum number of iterations.\n",
    "        convergence_threshold: Convergence threshold for optimization.\n",
    "    Returns:\n",
    "        control_amplitudes: Optimized control amplitudes.\n",
    "        fidelities: List of fidelity values during optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def neg_fidelity(params, **kwargs):\n",
    "        return -_fidelity(params, **kwargs)\n",
    "    opt = optax.lbfgs()\n",
    "\n",
    "    value_and_grad_fn = optax.value_and_grad_from_state(neg_fidelity)\n",
    "\n",
    "\n",
    "    def step(carry):\n",
    "        control_amplitudes, state , iter_idx = carry\n",
    "        value, grad = value_and_grad_fn(control_amplitudes, state=state)\n",
    "        updates, state = opt.update(\n",
    "            grad,\n",
    "            state,\n",
    "            control_amplitudes,\n",
    "            value=value,\n",
    "            grad=grad,\n",
    "            value_fn=neg_fidelity,\n",
    "        )\n",
    "        control_amplitudes = optax.apply_updates(control_amplitudes, updates)\n",
    "        return control_amplitudes, state, iter_idx + 1\n",
    "\n",
    "    def continuing_criterion(carry):\n",
    "        _, state, _ = carry\n",
    "        iter_num = otu.tree_get(state, 'count')\n",
    "        grad = otu.tree_get(state, 'grad')\n",
    "        err = otu.tree_l2_norm(grad)\n",
    "        return (iter_num == 0) | (\n",
    "            (iter_num < max_iter - 1) & (err >= convergence_threshold)\n",
    "        )\n",
    "\n",
    "    init_carry = (control_amplitudes, opt.init(control_amplitudes), 0)\n",
    "    final_params, _, final_iter_idx= jax.lax.while_loop(\n",
    "        continuing_criterion, step, init_carry\n",
    "    )\n",
    "    final_fidelity = _fidelity(final_params)\n",
    "    return final_params, final_fidelity, final_iter_idx\n",
    "\n",
    "\n",
    "# for unitary evolution (not using density operator)\n",
    "def optimize_pulse(\n",
    "    H_drift: jnp.ndarray,\n",
    "    H_control: list[jnp.ndarray],\n",
    "    U_0: jnp.ndarray,\n",
    "    C_target: jnp.ndarray,\n",
    "    num_t_slots: int,\n",
    "    total_evo_time: float,\n",
    "    max_iter: int = 1000,\n",
    "    convergence_threshold: float = 1e-6,\n",
    "    learning_rate: float = 0.01,\n",
    "    type: str = \"unitary\",\n",
    "    optimizer: str = \"adam\",\n",
    ") -> result:\n",
    "    \"\"\"\n",
    "    Uses GRAPE to optimize a pulse.\n",
    "\n",
    "    Args:\n",
    "        H_drift: Drift Hamiltonian.\n",
    "        H_control: List of Control Hamiltonians.\n",
    "        U_0: Initial density operator.\n",
    "        C_target: Target operator.\n",
    "        num_t_slots: Number of time slots.\n",
    "        total_evo_time: Total evolution time.\n",
    "        max_iter: Maximum number of iterations.\n",
    "        convergence_threshold: Convergence threshold for _fidelity change.\n",
    "        learning_rate: Learning rate for gradient ascent.\n",
    "    Returns:\n",
    "        result: Dictionary containing optimized pulse and convergence data.\n",
    "    \"\"\"\n",
    "    # Step 1: Initialize control amplitudes\n",
    "    control_amplitudes = _init_control_amplitudes(num_t_slots, len(H_control))\n",
    "    delta_t = total_evo_time / num_t_slots\n",
    "\n",
    "    # Convert H_control to array for easier manipulation\n",
    "    H_control_array = jnp.array(H_control)\n",
    "\n",
    "    def _fidelity(control_amplitudes):\n",
    "        propagators = _compute_propagators(\n",
    "            H_drift, H_control_array, delta_t, control_amplitudes\n",
    "        )\n",
    "        U_final = _compute_forward_evolution(propagators, U_0)\n",
    "\n",
    "        if type == \"unitary\":\n",
    "            overlap = (\n",
    "                jnp.trace(jnp.matmul(C_target.conj().T, U_final))\n",
    "                / C_target.shape[0]\n",
    "            )\n",
    "        else:\n",
    "            # TODO: check accuracy of this, do we really need vector conjugate or .dot will simply work?\n",
    "            norm_C_target = C_target / jnp.linalg.norm(C_target)\n",
    "            norm_U_final = U_final / jnp.linalg.norm(U_final)\n",
    "\n",
    "            overlap = jnp.vdot(norm_C_target, norm_U_final)\n",
    "        return jnp.abs(overlap) ** 2\n",
    "\n",
    "    # Step 2: Gradient ascent loop\n",
    "\n",
    "    if optimizer.upper() == \"L-BFGS\":\n",
    "        control_amplitudes, final_fidelity, iter_idx = _optimize_L_BFGS(\n",
    "            _fidelity,\n",
    "            control_amplitudes,\n",
    "            max_iter,\n",
    "            convergence_threshold,\n",
    "        )\n",
    "    else:\n",
    "        control_amplitudes, final_fidelity, iter_idx = _optimize_adam(\n",
    "            _fidelity,\n",
    "            control_amplitudes,\n",
    "            max_iter,\n",
    "            learning_rate,\n",
    "            convergence_threshold,\n",
    "        )\n",
    "\n",
    "    propagators = _compute_propagators(\n",
    "        H_drift, H_control_array, delta_t, control_amplitudes\n",
    "    )\n",
    "    rho_final = _compute_forward_evolution(propagators, U_0)\n",
    "\n",
    "    final_res = result(\n",
    "        control_amplitudes,\n",
    "        final_fidelity,\n",
    "        iter_idx + 1,\n",
    "        rho_final,\n",
    "    )\n",
    "\n",
    "    return final_res\n",
    "\n",
    "\n",
    "def plot_control_amplitudes(times, final_amps, labels):\n",
    "    \"\"\"\n",
    "    Plot control amplitudes with fixed y-axis scale highlighting each control\n",
    "    amplitude with respect to the other in its respective plot.\n",
    "\n",
    "    Args:\n",
    "        times: Time points for the x-axis.\n",
    "        final_amps: Control amplitudes to plot.\n",
    "        labels: Labels for each control amplitude.\n",
    "    \"\"\"\n",
    "\n",
    "    num_controls = final_amps.shape[1]\n",
    "\n",
    "    # y_max = 0.1  # Fixed y-axis scale\n",
    "    # y_min = -0.1\n",
    "\n",
    "    for i in range(num_controls):\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "        for j in range(num_controls):\n",
    "            color = (\n",
    "                'black' if i == j else 'gray'\n",
    "            )  # Highlight the current control\n",
    "            alpha = 1.0 if i == j else 0.1\n",
    "            ax.plot(\n",
    "                times,\n",
    "                final_amps[:, j],\n",
    "                label=labels[j],\n",
    "                color=color,\n",
    "                alpha=alpha,\n",
    "            )\n",
    "        ax.set_title(f\"Control Fields Highlighting: {labels[i]}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(labels[i])\n",
    "        # ax.set_ylim(y_min, y_max)  # Set fixed y-axis limits\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feedback_grape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mqutip_qtrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpulseoptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mqtrl\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedback_grape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_pulse\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedback_grape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedback_grape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feedback_grape'"
     ]
    }
   ],
   "source": [
    "## MAIN.py with time_dep example\n",
    "\n",
    "import jax\n",
    "import qutip as qt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import qutip_qtrl.pulseoptim as qtrl\n",
    "from feedback_grape.grape import optimize_pulse\n",
    "from feedback_grape.utils.gates import *\n",
    "from feedback_grape.utils.operators import *\n",
    "from feedback_grape.utils.tensor import tensor\n",
    "from feedback_grape.utils.states import basis\n",
    "# ruff: noqa\n",
    "\n",
    "N_cav = 10\n",
    "chi = 0.2385 * (2 * jnp.pi)\n",
    "mu_qub = 4.0\n",
    "mu_cav = 8.0\n",
    "hconj = lambda a: jnp.swapaxes(a.conj(), -1, -2)\n",
    "\n",
    "\n",
    "@jax.vmap\n",
    "def build_ham(e_qub, e_cav):\n",
    "    \"\"\"\n",
    "    Build Hamiltonian for given (complex) e_qub and e_cav\n",
    "    \"\"\"\n",
    "\n",
    "    a = tensor(identity(2), destroy(N_cav))\n",
    "    adag = hconj(a)\n",
    "    n_phot = adag @ a\n",
    "    sigz = tensor(sigmaz(), identity(N_cav))\n",
    "    sigp = tensor(sigmap(), identity(N_cav))\n",
    "    one = tensor(identity(2), identity(N_cav))\n",
    "\n",
    "    H0 = +(chi / 2) * n_phot @ (sigz + one)\n",
    "    H_ctrl_qub = mu_qub * sigp\n",
    "    H_ctrl_qub_dag = hconj(H_ctrl_qub)\n",
    "    H_ctrl_cav = mu_cav * adag\n",
    "    H_ctrl_cav_dag = hconj(H_ctrl_cav)\n",
    "\n",
    "    H_ctrl = [H_ctrl_qub, H_ctrl_qub_dag, H_ctrl_cav, H_ctrl_cav_dag]\n",
    "\n",
    "    H_ctrl = mu_qub * sigp * e_qub + mu_cav * adag * e_cav\n",
    "    H_ctrl += hconj(H_ctrl)\n",
    "    # You just pass an array of the Hamiltonian matrices \"Hs\" corresponding to the time\n",
    "    # intervals \"delta_ts\" (that is, \"Hs\" is a 3D array).\n",
    "    return H0, H_ctrl\n",
    "\n",
    "\n",
    "def build_grape_format_ham():\n",
    "    \"\"\"\n",
    "    Build Hamiltonian for given (complex) e_qub and e_cav\n",
    "    \"\"\"\n",
    "\n",
    "    a = tensor(identity(2), destroy(N_cav))\n",
    "    adag = hconj(a)\n",
    "    n_phot = adag @ a\n",
    "    sigz = tensor(sigmaz(), identity(N_cav))\n",
    "    sigp = tensor(sigmap(), identity(N_cav))\n",
    "    one = tensor(identity(2), identity(N_cav))\n",
    "\n",
    "    H0 = +(chi / 2) * n_phot @ (sigz + one)\n",
    "    H_ctrl_qub = mu_qub * sigp\n",
    "    H_ctrl_qub_dag = hconj(H_ctrl_qub)\n",
    "    H_ctrl_cav = mu_cav * adag\n",
    "    H_ctrl_cav_dag = hconj(H_ctrl_cav)\n",
    "\n",
    "    H_ctrl = [H_ctrl_qub, H_ctrl_qub_dag, H_ctrl_cav, H_ctrl_cav_dag]\n",
    "\n",
    "    return H0, H_ctrl\n",
    "\n",
    "\n",
    "def test_time_dep():\n",
    "    time_start = 0.0\n",
    "    time_end = 1.0\n",
    "    time_intervals_num = 5\n",
    "    N_cav = 10\n",
    "    t_grid = jnp.linspace(time_start, time_end, time_intervals_num + 1)\n",
    "    delta_ts = t_grid[1:] - t_grid[:-1]\n",
    "    fake_random_key = jax.random.key(seed=0)\n",
    "    e_data = jax.random.uniform(\n",
    "        fake_random_key, shape=(4, len(delta_ts)), minval=-1, maxval=1\n",
    "    )\n",
    "    e_qub = e_data[0] + 1j * e_data[1]\n",
    "    e_cav = e_data[2] + 1j * e_data[3]\n",
    "    H0, H_ctrl = build_ham(e_qub, e_cav)\n",
    "\n",
    "    # Representation for time dependent Hamiltonian\n",
    "    def solve(Hs, delta_ts):\n",
    "        \"\"\"\n",
    "        Find evolution operator for piecewise Hs on time intervals delts_ts\n",
    "        \"\"\"\n",
    "        for i, (H, delta_t) in enumerate(zip(Hs, delta_ts)):\n",
    "            U_intv = jax.scipy.linalg.expm(-1j * H * delta_t)\n",
    "            U = U_intv if i == 0 else U_intv @ U\n",
    "        return U\n",
    "\n",
    "    U = solve(H0 + H_ctrl, delta_ts)\n",
    "    psi0 = tensor(basis(2), basis(N_cav))\n",
    "    psi = U @ psi0\n",
    "\n",
    "    print(f\"psi0: {psi0.shape}\")\n",
    "\n",
    "    H0_grape, H_ctrl_grape = build_grape_format_ham()\n",
    "\n",
    "    res = optimize_pulse(\n",
    "        H0_grape,\n",
    "        H_ctrl_grape,\n",
    "        psi0,\n",
    "        psi,\n",
    "        int(\n",
    "            (time_end - time_start) / delta_ts[0]\n",
    "        ),  # Ensure this is an integer\n",
    "        time_end - time_start,\n",
    "        max_iter=10000,\n",
    "        convergence_threshold=1e-13,\n",
    "        learning_rate=1e-1,\n",
    "        type=\"state\",\n",
    "        optimizer=\"adam\",\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_time_dep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psi0: (20, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'optax' has no attribute 'lbfgs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_time_dep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 100\u001b[0m, in \u001b[0;36mtest_time_dep\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsi0: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpsi0\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m H0_grape, H_ctrl_grape \u001b[38;5;241m=\u001b[39m build_grape_format_ham()\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_pulse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43mH0_grape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43mH_ctrl_grape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43mpsi0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_ts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure this is an integer\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m \u001b[43m\u001b[49m\u001b[43mtime_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-13\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml-bfgs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 257\u001b[0m, in \u001b[0;36moptimize_pulse\u001b[0;34m(H_drift, H_control, U_0, C_target, num_t_slots, total_evo_time, max_iter, convergence_threshold, learning_rate, type, optimizer)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Step 2: Gradient ascent loop\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 257\u001b[0m     control_amplitudes, final_fidelity, iter_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_L_BFGS\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fidelity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontrol_amplitudes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     control_amplitudes, final_fidelity, iter_idx \u001b[38;5;241m=\u001b[39m _optimize_adam(\n\u001b[1;32m    265\u001b[0m         _fidelity,\n\u001b[1;32m    266\u001b[0m         control_amplitudes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m         convergence_threshold,\n\u001b[1;32m    270\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[10], line 162\u001b[0m, in \u001b[0;36m_optimize_L_BFGS\u001b[0;34m(_fidelity, control_amplitudes, max_iter, convergence_threshold)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mneg_fidelity\u001b[39m(params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m_fidelity(params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 162\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlbfgs\u001b[49m()\n\u001b[1;32m    164\u001b[0m value_and_grad_fn \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mvalue_and_grad_from_state(neg_fidelity)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(carry):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'optax' has no attribute 'lbfgs'"
     ]
    }
   ],
   "source": [
    "test_time_dep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = 0.0\n",
    "time_end = 1.0\n",
    "time_intervals_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid = jnp.linspace(time_start, time_end, time_intervals_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_labels = [r'$u_1$', r'$u_2$', r'$u_3$', r'$u_4$', r'$u_5$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_control_amplitudes(t_grid, result.control_amplitudes, labels=H_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tryng qutip's approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cav = 10\n",
    "chi = 0.2385 * (2 * jnp.pi)\n",
    "mu_qub = 4.0\n",
    "mu_cav = 8.0\n",
    "\n",
    "\n",
    "def build_ham_qt(e_qub, e_cav):\n",
    "    a = qt.tensor(qt.identity(2), qt.destroy(N_cav))\n",
    "    adag = a.dag()\n",
    "    n_phot = adag * a\n",
    "    sigz = qt.tensor(qt.sigmaz(), qt.identity(N_cav))\n",
    "    sigp = qt.tensor(qt.sigmap(), qt.identity(N_cav))\n",
    "    one = qt.tensor(qt.identity(2), qt.identity(N_cav))\n",
    "\n",
    "    H0 = +(chi / 2) * n_phot * (sigz + one)\n",
    "\n",
    "    H_ctrl_qub = mu_qub * sigp\n",
    "    H_ctrl_cav = mu_cav * adag\n",
    "\n",
    "    H = [\n",
    "        # time independent part\n",
    "        H0,\n",
    "        # time dependent on e_qub (you can consider e_qub an array of different coefficients each time step to\n",
    "        # represent changing Hamiltonian with time)\n",
    "        [H_ctrl_qub, e_qub],\n",
    "        # time dependent on e_qub.conj()\n",
    "        [H_ctrl_qub.dag(), e_qub.conj()],\n",
    "        # time dependent on e_cav\n",
    "        [H_ctrl_cav, e_cav],\n",
    "        # time dependent on e_cav.conj()\n",
    "        [H_ctrl_cav.dag(), e_cav.conj()],\n",
    "    ]\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "# Here it is essential to have to use np.repeat, np.array else it will output coefficient format not understood\n",
    "def test_time_dep_qt():\n",
    "    # Constants in Hamiltonian\n",
    "\n",
    "    time_start = 0.0\n",
    "    time_end = 1.0\n",
    "    time_intervals_num = 5\n",
    "    psi0_qt = qt.tensor(qt.basis(2), qt.basis(N_cav))\n",
    "    time_subintervals_num_qt = 100\n",
    "    t_grid_qt = np.linspace(\n",
    "        time_start, time_end, time_subintervals_num_qt * time_intervals_num\n",
    "    )\n",
    "\n",
    "    t_grid = np.linspace(time_start, time_end, time_intervals_num + 1)\n",
    "    delta_ts = t_grid[1:] - t_grid[:-1]\n",
    "    fake_random_key = jax.random.key(seed=0)\n",
    "    e_data = jax.random.uniform(\n",
    "        fake_random_key, shape=(4, len(delta_ts)), minval=-1, maxval=1\n",
    "    )\n",
    "    e_qub = e_data[0] + 1j * e_data[1]\n",
    "    e_cav = e_data[2] + 1j * e_data[3]\n",
    "    e_qub_qt = np.repeat(np.array(e_qub), time_subintervals_num_qt)\n",
    "    e_cav_qt = np.repeat(np.array(e_cav), time_subintervals_num_qt)\n",
    "    H_qt = build_ham_qt(e_qub_qt, e_cav_qt)\n",
    "    psi_qt = qt.sesolve(H_qt, psi0_qt, t_grid_qt).states[-1]\n",
    "\n",
    "    # Extract just the control operators from H_qt[1:] (not the coefficient arrays) (but that just completely discards the time dep part!)\n",
    "    # However, it is weird, because the fidelity is quite high\n",
    "    ctrls = [H_part[0] for H_part in H_qt[1:]]\n",
    "\n",
    "    result = qtrl.optimize_pulse(\n",
    "        H_qt[0],  # Drift Hamiltonian\n",
    "        ctrls,  # Pass just the control operators\n",
    "        psi0_qt,\n",
    "        psi_qt,\n",
    "        int(\n",
    "            (time_end - time_start) / delta_ts[0]\n",
    "        ),  # Ensure this is an integer\n",
    "        time_end - time_start,\n",
    "        max_iter=10000,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_dep_qt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - test_time_dep_qt().fid_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-stable8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
