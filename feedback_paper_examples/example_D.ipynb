{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76d2ebd",
   "metadata": {},
   "source": [
    "## State Stabilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d81979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"..\")\n",
    "from feedback_grape.fgrape import optimize_pulse_with_feedback\n",
    "from feedback_grape.utils.operators import (\n",
    "    sigmap,\n",
    "    sigmam,\n",
    "    create,\n",
    "    destroy,\n",
    "    identity,\n",
    "    cosm,\n",
    "    sinm,\n",
    ")\n",
    "from feedback_grape.utils.states import basis, fock\n",
    "from feedback_grape.utils.tensor import tensor\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe4baf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cav = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c912a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_unitary(alpha):\n",
    "    \"\"\"\n",
    "    TODO: see if alpha, can be sth elser other than scalar, and if the algo understands this\n",
    "    see if there can be multiple params like alpha and beta input\n",
    "    \"\"\"\n",
    "    return expm(\n",
    "        -1j\n",
    "        * (\n",
    "            alpha * tensor(identity(N_cav), sigmap())\n",
    "            + alpha.conjugate() * tensor(identity(N_cav), sigmam())\n",
    "        )\n",
    "        / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1baa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_cavity_unitary(beta):\n",
    "    return expm(\n",
    "        -1j\n",
    "        * (\n",
    "            beta\n",
    "            * (\n",
    "                tensor(destroy(N_cav), identity(2))\n",
    "                @ tensor(identity(N_cav), sigmap())\n",
    "            )\n",
    "            + beta.conjugate()\n",
    "            * (\n",
    "                tensor(create(N_cav), identity(2))\n",
    "                @ tensor(identity(N_cav), sigmam())\n",
    "            )\n",
    "        )\n",
    "        / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70a6a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def povm_measure_operator(measurement_outcome, gamma, delta):\n",
    "    \"\"\"\n",
    "    POVM for the measurement of the cavity state.\n",
    "    returns Mm ( NOT the POVM element Em = Mm_dag @ Mm ), given measurement_outcome m, gamma and delta\n",
    "    \"\"\"\n",
    "    number_operator = tensor(create(N_cav) @ destroy(N_cav), identity(2))\n",
    "    angle = (gamma * number_operator) + delta / 2\n",
    "    meas_op = jnp.where(\n",
    "        measurement_outcome == 1,\n",
    "        cosm(angle),\n",
    "        sinm(angle),\n",
    "    )\n",
    "    return meas_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e88143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state is a thermal state coupled to a qubit in the ground state?\n",
    "n_average = 9\n",
    "# natural logarithm\n",
    "beta = jnp.log((1 / n_average) + 1)\n",
    "diags = jnp.exp(-beta * jnp.arange(N_cav))\n",
    "normalized_diags = diags / jnp.sum(diags, axis=0)\n",
    "rho_cav = jnp.diag(normalized_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deb3eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho0 = tensor(rho_cav, basis(2, 0) @ basis(2, 0).conj().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47908f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce889fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.states import coherent\n",
    "\n",
    "alpha = 3\n",
    "psi_target = tensor(\n",
    "    coherent(N_cav, alpha)\n",
    "    + coherent(N_cav, -alpha)\n",
    "    + coherent(N_cav, 1j * alpha)\n",
    "    + coherent(N_cav, -1j * alpha),\n",
    "    basis(2),\n",
    ")  # 4-legged state\n",
    "\n",
    "rho_target = psi_target @ psi_target.conj().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2321d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6439b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20605832342551042\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(fidelity(U_final=rho0, C_target=rho_target, type=\"density\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab29059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    hidden_size: int  # number of features in the hidden state\n",
    "    output_size: int  # number of features in the output ( 2 in the case of gamma and beta)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, measurement, hidden_state):\n",
    "        \"\"\"\n",
    "        If your GRU has a hidden state increasing number of features in the hidden stateH means:\n",
    "\n",
    "        - You're allowing the model to store more information across time steps\n",
    "\n",
    "        - Each time step can represent more complex features, patterns, or dependencies\n",
    "\n",
    "        - You're giving the GRU more representational capacity\n",
    "        \"\"\"\n",
    "        gru_cell = nn.GRUCell(features=self.hidden_size)\n",
    "        self.make_rng('dropout')\n",
    "        if measurement.ndim == 1:\n",
    "            measurement = measurement.reshape(1, -1)\n",
    "        new_hidden_state, _ = gru_cell(hidden_state, measurement)\n",
    "        new_hidden_state = nn.Dropout(rate=0.2, deterministic=False)(\n",
    "            new_hidden_state\n",
    "        )\n",
    "        # this returns the povm_params after linear regression through the hidden state which contains\n",
    "        # the information of the previous time steps and this is optimized to output best povm_params\n",
    "        # new_hidden_state = nn.Dense(features=self.hidden_size)(new_hidden_state)\n",
    "        output = nn.Dense(\n",
    "            features=self.output_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "            bias_init=nn.initializers.constant(jnp.pi),\n",
    "        )(new_hidden_state)\n",
    "        # output = jnp.asarray(output)\n",
    "        return output[0], new_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2b30f",
   "metadata": {},
   "source": [
    "### Without dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5329d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: -0.191833\n",
      "Iteration 10, Loss: -0.352869\n",
      "Iteration 20, Loss: -0.503874\n",
      "Iteration 30, Loss: -0.539174\n",
      "Iteration 40, Loss: -0.582511\n",
      "Iteration 50, Loss: -0.624338\n",
      "Iteration 60, Loss: -0.665082\n",
      "Iteration 70, Loss: -0.706828\n",
      "Iteration 80, Loss: -0.749155\n",
      "Iteration 90, Loss: -0.791993\n",
      "Iteration 100, Loss: -0.835120\n",
      "Iteration 110, Loss: -0.878371\n",
      "Iteration 120, Loss: -0.921594\n",
      "Iteration 130, Loss: -0.964625\n",
      "Iteration 140, Loss: -1.007331\n",
      "Iteration 150, Loss: -1.049592\n",
      "Iteration 160, Loss: -1.091303\n",
      "Iteration 170, Loss: -1.132371\n",
      "Iteration 180, Loss: -1.172718\n",
      "Iteration 190, Loss: -1.212272\n",
      "Iteration 200, Loss: -1.250976\n",
      "Iteration 210, Loss: -1.288779\n",
      "Iteration 220, Loss: -1.325638\n",
      "Iteration 230, Loss: -1.361518\n",
      "Iteration 240, Loss: -1.396392\n",
      "Iteration 250, Loss: -1.430235\n",
      "Iteration 260, Loss: -1.463031\n",
      "Iteration 270, Loss: -1.494768\n",
      "Iteration 280, Loss: -1.525438\n",
      "Iteration 290, Loss: -1.555037\n",
      "Iteration 300, Loss: -1.583566\n",
      "Iteration 310, Loss: -1.611028\n",
      "Iteration 320, Loss: -1.637430\n",
      "Iteration 330, Loss: -1.662782\n",
      "Iteration 340, Loss: -1.687095\n",
      "Iteration 350, Loss: -1.710385\n",
      "Iteration 360, Loss: -1.732668\n",
      "Iteration 370, Loss: -1.753962\n",
      "Iteration 380, Loss: -1.774288\n",
      "Iteration 390, Loss: -1.793668\n",
      "Iteration 400, Loss: -1.812124\n",
      "Iteration 410, Loss: -1.829680\n",
      "Iteration 420, Loss: -1.846363\n",
      "Iteration 430, Loss: -1.862177\n",
      "Iteration 440, Loss: -1.877142\n",
      "Iteration 450, Loss: -1.891400\n",
      "Iteration 460, Loss: -1.904859\n",
      "Iteration 470, Loss: -1.917573\n",
      "Iteration 480, Loss: -1.929573\n",
      "Iteration 490, Loss: -1.940886\n",
      "Iteration 500, Loss: -1.951540\n",
      "Iteration 510, Loss: -1.961564\n",
      "Iteration 520, Loss: -1.970984\n",
      "Iteration 530, Loss: -1.979829\n",
      "Iteration 540, Loss: -1.988129\n",
      "Iteration 550, Loss: -1.995916\n",
      "Iteration 560, Loss: -2.003252\n",
      "Iteration 570, Loss: -2.010300\n",
      "Iteration 580, Loss: -2.017687\n",
      "Iteration 590, Loss: -2.028536\n",
      "Iteration 600, Loss: -2.070626\n",
      "Iteration 610, Loss: -2.294961\n",
      "Iteration 620, Loss: -2.309868\n",
      "Iteration 630, Loss: -2.322534\n",
      "Iteration 640, Loss: -2.331669\n",
      "Iteration 650, Loss: -2.338371\n",
      "Iteration 660, Loss: -2.343652\n",
      "Iteration 670, Loss: -2.348109\n",
      "Iteration 680, Loss: -2.352039\n",
      "Iteration 690, Loss: -2.355571\n",
      "Iteration 700, Loss: -2.358764\n",
      "Iteration 710, Loss: -2.361651\n",
      "Iteration 720, Loss: -2.364215\n",
      "Iteration 730, Loss: -2.366607\n",
      "Iteration 740, Loss: -2.368726\n",
      "Iteration 750, Loss: -2.370631\n",
      "Iteration 760, Loss: -2.372342\n",
      "Iteration 770, Loss: -2.373877\n",
      "Iteration 780, Loss: -2.375254\n",
      "Iteration 790, Loss: -2.376486\n",
      "Iteration 800, Loss: -2.377588\n",
      "Iteration 810, Loss: -2.378572\n",
      "Iteration 820, Loss: -2.379449\n",
      "Iteration 830, Loss: -2.380231\n",
      "Iteration 840, Loss: -2.380926\n",
      "Iteration 850, Loss: -2.381544\n",
      "Iteration 860, Loss: -2.382093\n",
      "Iteration 870, Loss: -2.382579\n",
      "Iteration 880, Loss: -2.383006\n",
      "Iteration 890, Loss: -2.383388\n",
      "Iteration 900, Loss: -2.383719\n",
      "Iteration 910, Loss: -2.384022\n",
      "Iteration 920, Loss: -2.384283\n",
      "Iteration 930, Loss: -2.384513\n",
      "Iteration 940, Loss: -2.384715\n",
      "Iteration 950, Loss: -2.384892\n",
      "Iteration 960, Loss: -2.385047\n",
      "Iteration 970, Loss: -2.385183\n",
      "Iteration 980, Loss: -2.385302\n",
      "Iteration 990, Loss: -2.385406\n"
     ]
    }
   ],
   "source": [
    "result = optimize_pulse_with_feedback(\n",
    "    U_0=rho_target,\n",
    "    C_target=rho_target,\n",
    "    parameterized_gates=[\n",
    "        povm_measure_operator,\n",
    "        qubit_unitary,\n",
    "        qubit_cavity_unitary,\n",
    "    ],\n",
    "    measurement_indices=[0],\n",
    "    initial_params = {\n",
    "        \"POVM\": [0.0, jnp.pi / 3],\n",
    "        \"U_q\": [jnp.pi / 2],\n",
    "        \"U_qc\": [jnp.pi / 2],\n",
    "    },\n",
    "    num_time_steps=1,\n",
    "    mode=\"lookup\",\n",
    "    goal=\"fidelity\",\n",
    "    optimizer=\"adam\",\n",
    "    max_iter=1000,\n",
    "    convergence_threshold=1e-6,\n",
    "    learning_rate=0.005,\n",
    "    type=\"density\",\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "242b562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999759638777322\n"
     ]
    }
   ],
   "source": [
    "print(result.final_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "546d79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 0.20605832342551042\n",
      "fidelity of state 0: 0.9997596387773222\n",
      "fidelity of state 1: 0.9997596387773222\n",
      "fidelity of state 2: 0.9997596387773222\n",
      "fidelity of state 3: 0.9997596387773222\n",
      "fidelity of state 4: 0.9997596387773222\n",
      "fidelity of state 5: 0.9997596387773222\n",
      "fidelity of state 6: 0.9997596387773222\n",
      "fidelity of state 7: 0.9997596387773222\n",
      "fidelity of state 8: 0.9997596387773222\n",
      "fidelity of state 9: 0.9997596387773222\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho0, type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, type=\"density\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2190e32",
   "metadata": {},
   "source": [
    "### With Dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize_pulse_with_feedback(\n",
    "    U_0=rho_target,\n",
    "    C_target=rho_target,\n",
    "    parameterized_gates=[\n",
    "        povm_measure_operator,\n",
    "        qubit_unitary,\n",
    "        qubit_cavity_unitary,\n",
    "    ],\n",
    "    measurement_indices=[0],\n",
    "    decay = {\n",
    "        \"decay_indices\": [0,1], # indices of gates before which decay occurs\n",
    "        \"decay_rates\": [0.01, 0.01], # decay rates for each gate\n",
    "        \"decay_durations\": [1, 1], # duration of decay for each gate\n",
    "    },\n",
    "    initial_params = {\n",
    "        \"POVM\": [0.0, jnp.pi / 3],\n",
    "        \"U_q\": [jnp.pi / 2],\n",
    "        \"U_qc\": [jnp.pi / 2],\n",
    "    },\n",
    "    num_time_steps=1,\n",
    "    mode=\"lookup\",\n",
    "    goal=\"fidelity\",\n",
    "    optimizer=\"adam\",\n",
    "    max_iter=1000,\n",
    "    convergence_threshold=1e-6,\n",
    "    learning_rate=0.005,\n",
    "    type=\"density\",\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
