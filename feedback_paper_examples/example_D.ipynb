{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81979c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"..\")\n",
    "from feedback_grape.fgrape import optimize_pulse_with_feedback\n",
    "from feedback_grape.utils.operators import (\n",
    "    sigmap,\n",
    "    sigmam,\n",
    "    create,\n",
    "    destroy,\n",
    "    identity,\n",
    "    cosm,\n",
    "    sinm,\n",
    ")\n",
    "from feedback_grape.utils.states import basis, fock\n",
    "from feedback_grape.utils.tensor import tensor\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4baf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cav = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c912a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_unitary(alpha):\n",
    "    \"\"\"\n",
    "    TODO: see if alpha, can be sth elser other than scalar, and if the algo understands this\n",
    "    see if there can be multiple params like alpha and beta input\n",
    "    \"\"\"\n",
    "    return expm(\n",
    "        -1j\n",
    "        * (\n",
    "            alpha * tensor(identity(N_cav), sigmap())\n",
    "            + alpha.conjugate() * tensor(identity(N_cav), sigmam())\n",
    "        )\n",
    "        / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1baa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_cavity_unitary(beta):\n",
    "    return expm(\n",
    "        -1j\n",
    "        * (\n",
    "            beta\n",
    "            * (\n",
    "                tensor(destroy(N_cav), identity(2))\n",
    "                @ tensor(identity(N_cav), sigmap())\n",
    "            )\n",
    "            + beta.conjugate()\n",
    "            * (\n",
    "                tensor(create(N_cav), identity(2))\n",
    "                @ tensor(identity(N_cav), sigmam())\n",
    "            )\n",
    "        )\n",
    "        / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a6a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.operators import create, destroy\n",
    "\n",
    "\n",
    "def povm_measure_operator(measurement_outcome, gamma, delta):\n",
    "    \"\"\"\n",
    "    POVM for the measurement of the cavity state.\n",
    "    returns Mm ( NOT the POVM element Em = Mm_dag @ Mm ), given measurement_outcome m, gamma and delta\n",
    "    \"\"\"\n",
    "    number_operator = tensor(create(N_cav) @ destroy(N_cav), identity(2))\n",
    "    angle = (gamma * number_operator) + delta / 2\n",
    "    meas_op = jnp.where(\n",
    "        measurement_outcome == 1,\n",
    "        cosm(angle),\n",
    "        sinm(angle),\n",
    "    )\n",
    "    return meas_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e88143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state is a thermal state coupled to a qubit in the ground state?\n",
    "n_average = 9\n",
    "# natural logarithm\n",
    "beta = jnp.log((1 / n_average) + 1)\n",
    "diags = jnp.exp(-beta * jnp.arange(N_cav))\n",
    "normalized_diags = diags / jnp.sum(diags, axis=0)\n",
    "rho_cav = jnp.diag(normalized_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb3eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho0 = tensor(rho_cav, basis(2, 0) @ basis(2, 0).conj().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47908f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce889fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_grape.utils.states import coherent\n",
    "alpha = 3\n",
    "psi_target = tensor(coherent(N_cav, alpha) + coherent(N_cav, -alpha) + coherent(N_cav, 1j*alpha) + coherent(N_cav, -1j*alpha), basis(2)) # 4-legged state\n",
    "\n",
    "rho_target = psi_target @ psi_target.conj().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2321d333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6439b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20605832342551042\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(fidelity(U_final=rho0, C_target=rho_target, type=\"density\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab29059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "class RNN(nn.Module):\n",
    "    hidden_size: int  # number of features in the hidden state\n",
    "    output_size: int  # number of features in the output ( 2 in the case of gamma and beta)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, measurement, hidden_state):\n",
    "        \"\"\"\n",
    "        If your GRU has a hidden state increasing number of features in the hidden stateH means:\n",
    "\n",
    "        - You're allowing the model to store more information across time steps\n",
    "\n",
    "        - Each time step can represent more complex features, patterns, or dependencies\n",
    "\n",
    "        - You're giving the GRU more representational capacity\n",
    "        \"\"\"\n",
    "        gru_cell = nn.GRUCell(features=self.hidden_size)\n",
    "        self.make_rng('dropout')\n",
    "        if measurement.ndim == 1:\n",
    "            measurement = measurement.reshape(1, -1)\n",
    "        new_hidden_state, _ = gru_cell(hidden_state, measurement)\n",
    "        new_hidden_state = nn.Dropout(rate=0.2, deterministic=False)(\n",
    "            new_hidden_state\n",
    "        )\n",
    "        # this returns the povm_params after linear regression through the hidden state which contains\n",
    "        # the information of the previous time steps and this is optimized to output best povm_params\n",
    "        # new_hidden_state = nn.Dense(features=self.hidden_size)(new_hidden_state)\n",
    "        output = nn.Dense(\n",
    "            features=self.output_size,\n",
    "            kernel_init=nn.initializers.glorot_uniform(),\n",
    "            bias_init=nn.initializers.constant(jnp.pi),\n",
    "        )(new_hidden_state)\n",
    "        # output = jnp.asarray(output)\n",
    "        return output[0], new_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329d87d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# avg_photon_numer = 2 When testing kitten state\u001b[39;00m\n\u001b[32m      7\u001b[39m initial_params = {\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPOVM\u001b[39m\u001b[33m\"\u001b[39m: [jnp.pi / \u001b[32m3\u001b[39m, jnp.pi / \u001b[32m3\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mU_q\u001b[39m\u001b[33m\"\u001b[39m: [jnp.pi / \u001b[32m3\u001b[39m],\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mU_qc\u001b[39m\u001b[33m\"\u001b[39m: [jnp.pi / \u001b[32m3\u001b[39m],\n\u001b[32m     11\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result = \u001b[43moptimize_pulse_with_feedback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mU_0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrho0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrho_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpovm_measure_operator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqubit_unitary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqubit_cavity_unitary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# decay= {\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"decay_indices\": [0,1], # indices of gates before which decay occurs\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"decay_rates\": [0.01, 0.01], # decay rates for each gate\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"decay_durations\": [1, 1], # duration of decay for each gate\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# }\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_time_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_time_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlookup\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgoal\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfidelity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_of_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdensity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# RNN=RNN\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:531\u001b[39m, in \u001b[36moptimize_pulse_with_feedback\u001b[39m\u001b[34m(U_0, C_target, parameterized_gates, measurement_indices, initial_params, goal, mode, num_time_steps, optimizer, max_iter, convergence_threshold, learning_rate, type, batch_size, decay, RNN)\u001b[39m\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss1 + loss2\n\u001b[32m    529\u001b[39m key, sub_key = jax.random.split(parent_rng_key)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m best_model_params, iter_idx = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    541\u001b[39m result = evaluate(\n\u001b[32m    542\u001b[39m     U_0=U_0,\n\u001b[32m    543\u001b[39m     C_target=C_target,\n\u001b[32m   (...)\u001b[39m\u001b[32m    558\u001b[39m     num_iterations=iter_idx,\n\u001b[32m    559\u001b[39m )\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:579\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(optimizer, loss_fn, trainable_params, prng_key, max_iter, learning_rate, convergence_threshold)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Optimization\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;66;03m# set up optimizer and training state\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizer.upper() == \u001b[33m\"\u001b[39m\u001b[33mADAM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     best_model_params, iter_idx = \u001b[43m_optimize_adam_feedback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvergence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m optimizer.upper() == \u001b[33m\"\u001b[39m\u001b[33mL-BFGS\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# TODO: implement L-BFGS for feedback version\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mL-BFGS optimizer is not implemented for feedback version yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    591\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/utils/optimizers.py:68\u001b[39m, in \u001b[36m_optimize_adam_feedback\u001b[39m\u001b[34m(loss_fn, control_amplitudes, max_iter, learning_rate, convergence_threshold, key)\u001b[39m\n\u001b[32m     66\u001b[39m iter_idx = -\u001b[32m1\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m iter_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     params, opt_state, loss, key = \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     losses.append(loss)\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     71\u001b[39m         iter_idx > \u001b[32m0\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(losses[-\u001b[32m1\u001b[39m] - losses[-\u001b[32m2\u001b[39m]) < convergence_threshold\n\u001b[32m     73\u001b[39m     ):\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/utils/optimizers.py:57\u001b[39m, in \u001b[36m_optimize_adam_feedback.<locals>.step\u001b[39m\u001b[34m(params, state, key)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;129m@jax\u001b[39m.jit\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(params, state, key):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Minimize -loss_fn\u001b[39;00m\n\u001b[32m     58\u001b[39m     grads = jax.grad(\u001b[38;5;28;01mlambda\u001b[39;00m x, k: loss_fn(x, k))(params, key)\n\u001b[32m     59\u001b[39m     updates, new_state = optimizer.update(grads, state, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:484\u001b[39m, in \u001b[36moptimize_pulse_with_feedback.<locals>.loss_fn\u001b[39m\u001b[34m(trainable_params, rng_key)\u001b[39m\n\u001b[32m    481\u001b[39m     rnn_params = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    482\u001b[39m     lookup_table_params = trainable_params\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m rho_final, log_prob, _ = \u001b[43mcalculate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrho_cav\u001b[49m\u001b[43m=\u001b[49m\u001b[43mU_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_time_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrnn_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_initial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlut\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookup_table_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m goal == \u001b[33m\"\u001b[39m\u001b[33mpurity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    501\u001b[39m     purity_values = jax.vmap(purity)(rho=rho_final)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:347\u001b[39m, in \u001b[36mcalculate_trajectory\u001b[39m\u001b[34m(rho_cav, parameterized_gates, measurement_indices, decay, initial_params, param_shapes, time_steps, rnn_model, rnn_params, rnn_state, lut, type, batch_size, rng_key)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Use jax.vmap to vectorize the trajectory calculation for batch_size\u001b[39;00m\n\u001b[32m    330\u001b[39m batched_trajectory_fn = jax.vmap(\n\u001b[32m    331\u001b[39m     _calculate_single_trajectory,\n\u001b[32m    332\u001b[39m     in_axes=(\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m     ),\n\u001b[32m    346\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbatched_trajectory_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrho_final_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnn_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlut\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrng_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 7 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:275\u001b[39m, in \u001b[36mcalculate_trajectory.<locals>._calculate_single_trajectory\u001b[39m\u001b[34m(rho_cav, parameterized_gates, measurement_indices, decay, initial_params, param_shapes, rnn_model, rnn_params, hidden_state, lut, type, rng_key)\u001b[39m\n\u001b[32m    267\u001b[39m measurement_history = []\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(time_steps):\n\u001b[32m    269\u001b[39m     (\n\u001b[32m    270\u001b[39m         rho_final,\n\u001b[32m    271\u001b[39m         log_prob,\n\u001b[32m    272\u001b[39m         new_params,\n\u001b[32m    273\u001b[39m         applied_params,\n\u001b[32m    274\u001b[39m         measurement_history,\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     ) = \u001b[43m_calculate_time_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrho_cav\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrho_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameterized_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeasurement_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlut\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlut\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmeasurement_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeasurement_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_step_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# Thus, during - Refer to Eq(3) in fgrape paper\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;66;03m# the individual time-evolution trajectory, this term may\u001b[39;00m\n\u001b[32m    289\u001b[39m     \u001b[38;5;66;03m# be easily accumulated step by step, since the conditional\u001b[39;00m\n\u001b[32m    290\u001b[39m     \u001b[38;5;66;03m# probabilities are known (these are just the POVM mea-\u001b[39;00m\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# surement probabilities)\u001b[39;00m\n\u001b[32m    292\u001b[39m     total_log_prob += log_prob\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape.py:126\u001b[39m, in \u001b[36m_calculate_time_step\u001b[39m\u001b[34m(rho_cav, parameterized_gates, measurement_indices, decay, initial_params, param_shapes, rnn_model, rnn_params, rnn_state, lut, measurement_history, type, rng_key)\u001b[39m\n\u001b[32m    124\u001b[39m measurement_history.append(measurement)\n\u001b[32m    125\u001b[39m applied_params.append(extracted_lut_params[i])\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m extracted_lut_params = \u001b[43mextract_from_lut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasurement_history\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m extracted_lut_params = reshape_params(\n\u001b[32m    130\u001b[39m     param_shapes, extracted_lut_params\n\u001b[32m    131\u001b[39m )\n\u001b[32m    132\u001b[39m total_log_prob += log_prob\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/feedback_paper_examples/../feedback_grape/fgrape_helpers.py:55\u001b[39m, in \u001b[36mextract_from_lut\u001b[39m\u001b[34m(lut, measurement_history)\u001b[39m\n\u001b[32m     53\u001b[39m sub_array_idx = \u001b[38;5;28mlen\u001b[39m(measurement_history) - \u001b[32m1\u001b[39m\n\u001b[32m     54\u001b[39m sub_array_param_idx = convert_to_index(measurement_history)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlut\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43msub_array_idx\u001b[49m\u001b[43m]\u001b[49m[sub_array_param_idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/.conda/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[39m, in \u001b[36m_forward_operator_to_aval.<locals>.op\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/.conda/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:652\u001b[39m, in \u001b[36m_getitem\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/.conda/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:633\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[39m\n\u001b[32m    630\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m lax.dynamic_index_in_dim(arr, idx, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    632\u001b[39m treedef, static_idx, dynamic_idx = split_index_for_jit(idx, arr.shape)\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_sharding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/.conda/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:642\u001b[39m, in \u001b[36m_gather\u001b[39m\u001b[34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[32m    640\u001b[39m             unique_indices, mode, fill_value, out_sharding):\n\u001b[32m    641\u001b[39m   idx = merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m   indexer = \u001b[43mindex_to_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shared with _scatter_update\u001b[39;00m\n\u001b[32m    643\u001b[39m   y = arr\n\u001b[32m    645\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/dev/FeedBack-GRAPE/.conda/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:890\u001b[39m, in \u001b[36mindex_to_gather\u001b[39m\u001b[34m(x_shape, idx, normalize_indices)\u001b[39m\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(abstract_i, core.ShapedArray) \u001b[38;5;129;01mand\u001b[39;00m _int(abstract_i):\n\u001b[32m    888\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m core.definitely_equal(x_shape[x_axis], \u001b[32m0\u001b[39m):\n\u001b[32m    889\u001b[39m     \u001b[38;5;66;03m# XLA gives error when indexing into an axis of size 0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindex is out of bounds for axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_axis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with size 0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    891\u001b[39m   i = _normalize_index(i, x_shape[x_axis]) \u001b[38;5;28;01mif\u001b[39;00m normalize_indices \u001b[38;5;28;01melse\u001b[39;00m i\n\u001b[32m    892\u001b[39m   i_converted = lax.convert_element_type(i, index_dtype)\n",
      "\u001b[31mIndexError\u001b[39m: index is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "num_time_steps = 2\n",
    "num_of_iterations = 1000\n",
    "learning_rate = 0.005\n",
    "# avg_photon_numer = 2 When testing kitten state\n",
    "\n",
    "\n",
    "initial_params = {\n",
    "    \"POVM\": [jnp.pi / 3, jnp.pi / 3],\n",
    "    \"U_q\": [jnp.pi / 3],\n",
    "    \"U_qc\": [jnp.pi / 3],\n",
    "}\n",
    "\n",
    "\n",
    "result = optimize_pulse_with_feedback(\n",
    "    U_0=rho0,\n",
    "    C_target=rho_target,\n",
    "    parameterized_gates=[\n",
    "        povm_measure_operator,\n",
    "        qubit_unitary,\n",
    "        qubit_cavity_unitary,\n",
    "    ],\n",
    "    measurement_indices=[0],\n",
    "    # decay= {\n",
    "    #     \"decay_indices\": [0,1], # indices of gates before which decay occurs\n",
    "    #     \"decay_rates\": [0.01, 0.01], # decay rates for each gate\n",
    "    #     \"decay_durations\": [1, 1], # duration of decay for each gate\n",
    "    # }\n",
    "    initial_params=initial_params,\n",
    "    num_time_steps=num_time_steps,\n",
    "    mode=\"lookup\",\n",
    "    goal=\"fidelity\",\n",
    "    optimizer=\"adam\",\n",
    "    max_iter=num_of_iterations,\n",
    "    convergence_threshold=1e-20,\n",
    "    learning_rate=learning_rate,\n",
    "    type=\"density\",\n",
    "    batch_size=5,\n",
    "    # RNN=RNN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b562a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1886253048844297\n"
     ]
    }
   ],
   "source": [
    "print(result.final_fidelity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial fidelity: 0.20605832342551042\n",
      "fidelity of state 0: 0.18816671212747849\n",
      "fidelity of state 1: 0.1887213978913976\n",
      "fidelity of state 2: 0.18879422504834864\n",
      "fidelity of state 3: 0.18868666550225452\n",
      "fidelity of state 4: 0.1887575238526691\n"
     ]
    }
   ],
   "source": [
    "from feedback_grape.utils.fidelity import fidelity\n",
    "\n",
    "print(\n",
    "    \"initial fidelity:\",\n",
    "    fidelity(C_target=rho_target, U_final=rho0, type=\"density\"),\n",
    ")\n",
    "for i, state in enumerate(result.final_state):\n",
    "    print(\n",
    "        f\"fidelity of state {i}:\",\n",
    "        fidelity(C_target=rho_target, U_final=state, type=\"density\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5fd59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
